{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ea846f-d5a9-4f61-b3b1-fed90e2edde3",
   "metadata": {},
   "source": [
    "# RNN LSTM Explainer\n",
    "\n",
    "The goal is to walk through RNNs (recurring neural networks), there are 2 flavors: GRUs and LSTMs. We'll focus on Long Short-Term Memory (LSTM).\n",
    "\n",
    "To help display the transformation, we'll use the first sentence from the [linear algebra wiki page](https://en.wikipedia.org/wiki/Linear_algebra) and [lu decomposition wiki page](https://en.wikipedia.org/wiki/LU_decomposition) as the topic is fitting and it shows us some non-standard patterns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f8d05-f237-4a81-8f88-be839e4a9e51",
   "metadata": {},
   "source": [
    "## Text Prep/Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1237d-fd4f-43bc-ba02-88e82368b385",
   "metadata": {},
   "source": [
    "we'll start with common preprocessing step of tokenizing the data.  This converts the string text into an array of numbers that can be used during the training loop.  I've built a very subtle byte-pair encdoing that has each unique character that appears and the top 5 merges. This keeps our vocab size small and managable for this example. Typically the vocab size is in the 100K+ range. A great library for this is `tiktoken`. Tokenization simply finds the longest pattern of characters that's in common with what was trained and replaces it with an integer that represents it.  This way we turn the text into a numeric array to simplify computing. import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baeedf57-4218-4b0e-be46-217723a9034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2240c1-dd4e-4f8a-9fb1-acff3ff200c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBPETokenizer:\n",
    "    def __init__(self, num_merges=5, eot_token='<|endoftext|>'):\n",
    "        self.num_merges = num_merges\n",
    "        self.eot_token = eot_token\n",
    "        self.eot_id = None\n",
    "        self.merges = []\n",
    "        self.pair_ranks = {}\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "\n",
    "    def _add_token(self, tok):\n",
    "        if tok in self.vocab:\n",
    "            return self.vocab[tok]\n",
    "        i = len(self.vocab)\n",
    "        self.vocab[tok] = i\n",
    "        self.id_to_token[i] = tok\n",
    "        return i\n",
    "\n",
    "    def _get_bigrams(self, seq):\n",
    "        for i in range(len(seq) - 1):\n",
    "            yield (seq[i], seq[i + 1])\n",
    "\n",
    "    def _merge_once(self, seq, pair):\n",
    "        a, b = pair\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            if i < len(seq) - 1 and seq[i] == a and seq[i + 1] == b:\n",
    "                out.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                out.append(seq[i])\n",
    "                i += 1\n",
    "        return out\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # corpus: list[str]\n",
    "        text = ''.join(corpus).lower()\n",
    "        seq = list(text)\n",
    "        merges = []\n",
    "        for _ in range(self.num_merges):\n",
    "            counts = Counter(self._get_bigrams(seq))\n",
    "            if not counts: break\n",
    "            best_pair, _ = counts.most_common(1)[0]\n",
    "            merges.append(best_pair)\n",
    "            seq = self._merge_once(seq, best_pair)\n",
    "        self.merges = merges\n",
    "        self.pair_ranks = {p: i for i, p in enumerate(self.merges)}\n",
    "\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "        for ch in sorted(set(text)):\n",
    "            self._add_token(ch)\n",
    "        for a, b in self.merges:\n",
    "            self._add_token(a + b)\n",
    "        self.eot_id = self._add_token(self.eot_token)\n",
    "\n",
    "    def encode(self, text, force_last_eot=True):\n",
    "        # treat literal eot marker as special; remove it from content\n",
    "        if self.eot_token in text:\n",
    "            text = text.replace(self.eot_token, '')\n",
    "        seq = list(text)\n",
    "\n",
    "        # make sure all seen base chars exist\n",
    "        for ch in set(seq):\n",
    "            if ch not in self.vocab:\n",
    "                self._add_token(ch)\n",
    "\n",
    "        # greedy BPE using learned pair ranks\n",
    "        if self.merges:\n",
    "            while True:\n",
    "                best_pair, best_rank = None, None\n",
    "                for p in self._get_bigrams(seq):\n",
    "                    r = self.pair_ranks.get(p)\n",
    "                    if r is not None and (best_rank is None or r < best_rank):\n",
    "                        best_pair, best_rank = p, r\n",
    "                if best_pair is None:\n",
    "                    break\n",
    "                seq = self._merge_once(seq, best_pair)\n",
    "\n",
    "        # ensure all tokens in seq exist in vocab (e.g., if new chars appeared)\n",
    "        for tok in seq:\n",
    "            if tok not in self.vocab:\n",
    "                self._add_token(tok)\n",
    "\n",
    "        ids = [self.vocab[tok] for tok in seq]\n",
    "\n",
    "        # FORCE: append EOT id if not already last\n",
    "        if force_last_eot:\n",
    "            if not ids or ids[-1] != self.eot_id:\n",
    "                ids.append(self.eot_id)\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # drop trailing EOT if present\n",
    "        if ids and self.eot_id is not None and ids[-1] == self.eot_id:\n",
    "            ids = ids[:-1]\n",
    "        toks = [self.id_to_token[i] for i in ids]\n",
    "        return ''.join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35d09cf-0ce1-47a0-a93f-8213bea8f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_example_1 = r'''Linear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis, a branch of mathematical analysis, may be viewed as the application of linear algebra to function spaces.'''\n",
    "raw_example_2 = r'''In numerical analysis and linear algebra, lower–upper (LU) decomposition or factorization factors a matrix as the product of a lower triangular matrix and an upper triangular matrix (see matrix multiplication and matrix decomposition).'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7064c634-a608-4a62-93fe-c89219aa5dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 'a'), ('a', 't'), ('i', 'n'), (' ', 'm'), ('i', 'o')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = SimpleBPETokenizer(num_merges=5)\n",
    "tok.train([raw_example_1,raw_example_2])\n",
    "tok.merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133f8d70-16cd-4327-91a2-4e887612bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '(': 1,\n",
       " ')': 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " 'a': 5,\n",
       " 'b': 6,\n",
       " 'c': 7,\n",
       " 'd': 8,\n",
       " 'e': 9,\n",
       " 'f': 10,\n",
       " 'g': 11,\n",
       " 'h': 12,\n",
       " 'i': 13,\n",
       " 'j': 14,\n",
       " 'l': 15,\n",
       " 'm': 16,\n",
       " 'n': 17,\n",
       " 'o': 18,\n",
       " 'p': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " '–': 29,\n",
       " ' a': 30,\n",
       " 'at': 31,\n",
       " 'in': 32,\n",
       " ' m': 33,\n",
       " 'io': 34,\n",
       " '<|endoftext|>': 35}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9804d527-b590-4bb5-8158-8cdcbc179719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tok.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29443925-8749-4b7c-a500-4a3bdbf808d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0,  7,\n",
       "         9, 17, 22, 20,  5, 15,  0, 22, 18, 30, 15, 16, 18, 21, 22, 30, 15, 15,\n",
       "        30, 20,  9,  5, 21,  0, 18, 10, 33, 31, 12,  9, 16, 31, 13,  7, 21,  4,\n",
       "         0, 10, 18, 20,  0, 32, 21, 22,  5, 17,  7,  9,  3,  0, 15, 32,  9,  5,\n",
       "        20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0, 10, 23, 17,  8,  5, 16,\n",
       "         9, 17, 22,  5, 15,  0, 32, 33, 18,  8,  9, 20, 17,  0, 19, 20,  9, 21,\n",
       "         9, 17, 22, 31, 34, 17, 21,  0, 18, 10,  0, 11,  9, 18, 16,  9, 22, 20,\n",
       "        27,  3,  0, 32,  7, 15, 23,  8, 32, 11,  0, 10, 18, 20,  0,  8,  9, 10,\n",
       "        32, 32, 11,  0,  6,  5, 21, 13,  7,  0, 18,  6, 14,  9,  7, 22, 21,  0,\n",
       "        21, 23,  7, 12, 30, 21,  0, 15, 32,  9, 21,  3,  0, 19, 15,  5, 17,  9,\n",
       "        21, 30, 17,  8,  0, 20, 18, 22, 31, 34, 17, 21,  4, 30, 15, 21, 18,  3,\n",
       "         0, 10, 23, 17,  7, 22, 34, 17,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,\n",
       "         3, 30,  0,  6, 20,  5, 17,  7, 12,  0, 18, 10, 33, 31, 12,  9, 16, 31,\n",
       "        13,  7,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,  3, 33,  5, 27,  0,  6,\n",
       "         9,  0, 24, 13,  9, 25,  9,  8, 30, 21,  0, 22, 12,  9, 30, 19, 19, 15,\n",
       "        13,  7, 31, 34, 17,  0, 18, 10,  0, 15, 32,  9,  5, 20, 30, 15, 11,  9,\n",
       "         6, 20,  5,  0, 22, 18,  0, 10, 23, 17,  7, 22, 34, 17,  0, 21, 19,  5,\n",
       "         7,  9, 21,  4, 35, 35, 32,  0, 17, 23, 16,  9, 20, 13,  7,  5, 15, 30,\n",
       "        17,  5, 15, 27, 21, 13, 21, 30, 17,  8,  0, 15, 32,  9,  5, 20, 30, 15,\n",
       "        11,  9,  6, 20,  5,  3,  0, 15, 18, 25,  9, 20, 29, 23, 19, 19,  9, 20,\n",
       "         0,  1, 15, 23,  2,  0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,\n",
       "         0, 18, 20,  0, 10,  5,  7, 22, 18, 20, 13, 28, 31, 34, 17,  0, 10,  5,\n",
       "         7, 22, 18, 20, 21, 30, 33, 31, 20, 13, 26, 30, 21,  0, 22, 12,  9,  0,\n",
       "        19, 20, 18,  8, 23,  7, 22,  0, 18, 10, 30,  0, 15, 18, 25,  9, 20,  0,\n",
       "        22, 20, 13,  5, 17, 11, 23, 15,  5, 20, 33, 31, 20, 13, 26, 30, 17,  8,\n",
       "        30, 17,  0, 23, 19, 19,  9, 20,  0, 22, 20, 13,  5, 17, 11, 23, 15,  5,\n",
       "        20, 33, 31, 20, 13, 26,  0,  1, 21,  9,  9, 33, 31, 20, 13, 26, 33, 23,\n",
       "        15, 22, 13, 19, 15, 13,  7, 31, 34, 17, 30, 17,  8, 33, 31, 20, 13, 26,\n",
       "         0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,  2,  4, 35])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eot = tok.eot_id\n",
    "tokens = []\n",
    "for example in [raw_example_1, raw_example_2]:\n",
    "    tokens.extend([eot])\n",
    "    tokens.extend(tok.encode(example.lower()))\n",
    "all_tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f0cb1-fdac-400c-a80d-1a5da154434c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd76b6-dfd5-4f08-a289-630af13649f0",
   "metadata": {},
   "source": [
    "A machine learning model forward pass now uses the tokenization information, runs several layers of linear algebra on it, and then \"predicts\" the next token. When it is noisy (like you will see in this example), this process results in gibberish.  The training process changes the noise to pattern during the \"backward pass\" as you'll see.    We'll show 3 steps that are focused on training:\n",
    "1. **Data Loading** `x, y = train_loader.next_batch()` - this step pulls from the raw data enough tokens to complete a forward and backward pass.  If the model is inference only, this step is replaced with taking in the inference input and preparing it similarly as the forward pass.\n",
    "2. **Forward Pass** `logits, loss = model(x, y)` - using the data and the model architecture to predict the next token. When training we also compare against the expected to get loss, but in infrerence, we use the logits to complete the inference task.\n",
    "3. **Backward Pass & Training** `loss.backward(); optimizer.step()` - using differentials to understand what parameters most impact the forward pass' impact on its prediction, comparing that against what is actually right based on the data loading step, and then making very minor adjustments to the impactful parameters with the hope it improves future predictions.\n",
    "\n",
    "The we'll show a final **Forward Pass** with the updated weights we did in #3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8d4c4-ae00-465d-ae6f-ea6e1be858f0",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d7e34-19d0-4c9b-bc7c-b89c09052167",
   "metadata": {},
   "source": [
    "To start, we need to get enough data to run the forward and backward passes.  Since our total dataset is likely too big to hold all at once in real practice, we would read just enough file information into memory so that we can run the passes, leaving memory and compute to be used on the passes instead of static data holding. \n",
    "To start, we have to identify the batch size and the model context length to determine how much data we need.  Consequently, these dimensions also form 2 of the 3 dimensions in the initial matrix.\n",
    "- **Batch Size (B)** - This is the number of examples you'll train on in a single pass. \n",
    "- **Context Length (T)** - This is the max number of tokens that a model can use in a single pass to generat the next token. If an example is below this length, it can be padded.\n",
    "  \n",
    "*Ideally both B and T are multiples of 2 to work nicely with chip architecture. This is a common theme across the board*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1349878b-f4cd-4691-93fc-f8f2d76cb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2 # Batch\n",
    "T = 8 # context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eda05fa-9c31-4618-ae8c-ed1317467795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_position = 0\n",
    "tok_for_training = all_tokens[current_position:current_position + B*T +1 ]\n",
    "tok_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cc8223-0f42-4756-af7c-3af62ce59551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36ec177-74d7-4cb9-b84d-75a10a6c6694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35, 15, 32,  9,  5, 20, 30, 15],\n",
       "        [11,  9,  6, 20,  5,  0, 13, 21]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tok_for_training[:-1].view(B, T)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d87eb2-5bc8-44cb-80d4-806c3a3bf93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 32,  9,  5, 20, 30, 15, 11],\n",
       "        [ 9,  6, 20,  5,  0, 13, 21,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tok_for_training[1:].view(B, T)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd96f05-28c7-482a-bd47-d8226e65d235",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e785e1-7328-4b6f-83f9-a98247f06bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa762304-604b-458a-b0d5-2d787de76448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_batch, T_context = x.size()\n",
    "B_batch, T_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6d9984-9890-4b37-b538-5a09fdb7efed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 4 # level of embedding of input tokens\n",
    "n_embd, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3ccab-d62d-41f8-9539-4a257e9ca2a8",
   "metadata": {},
   "source": [
    "**Embedding input**\n",
    "\n",
    "Same as with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be607d75-1447-4339-9145-0f18f7e294b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wte = nn.Embedding(vocab_size, n_embd)\n",
    "torch.nn.init.ones_(wte.weight)\n",
    "wte.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b37914-4be6-4ed6-ad7b-daa43db954ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4]),\n",
       " tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wte(x)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf83182-f32a-4da0-93c8-8bb4f41cce49",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa012d0-91b1-474d-b961-ebfb4ef1889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.1, inplace=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.1)\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b56d86-9cfe-4b21-ba08-1b1dba07fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 0.0000, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111]],\n",
       "\n",
       "        [[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 0.0000],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [0.0000, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 0.0000, 1.1111, 1.1111]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbacb6-0960-4e47-b541-342263b58c57",
   "metadata": {},
   "source": [
    "**Recurrent Block**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c2ecb-580d-402c-b932-f00d799ab5b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In an LSTM at time (t): (i_t) is the input gate, (f_t) is the forget gate, (o_t) is the output gate, and (g_t) is the candidate cell content (sometimes written $\\tilde{c}_t)$. (c_t) is the cell state after update, and (h_t) is the hidden state (the exposed output).\n",
    "\n",
    "Using the usual affine “gate packs,” $x2g$ denotes the learned input-to-gates projection $W_x x_t + b_x \\in \\mathbb{R}^{4H}$ and $h2g$ the hidden-to-gates projection $W_h h_{t-1} + b_h \\in \\mathbb{R}^{4H}$. Their sum is split into four (H)-wide chunks to get the preactivations for the four gate blocks.\n",
    "\n",
    "The standard equations $with (x_t \\in \\mathbb{R}^{B\\times d}), (h_{t-1},h_t,c_{t-1},c_t \\in \\mathbb{R}^{B\\times H})$ are:\n",
    "$\n",
    "\\begin{aligned}\n",
    "[z_i, z_f, z_g, z_o] = x2g(x_t) + h2g(h_{t-1}) \\quad\\in \\mathbb{R}^{B\\times 4H},\\\n",
    "i_t &= \\sigma(z_i),\\qquad f_t=\\sigma(z_f),\\qquad g_t=\\tanh(z_g),\\qquad o_t=\\sigma(z_o),\\\n",
    "c_t &= f_t \\odot c_{t-1} + i_t \\odot g_t,\\\n",
    "h_t &= o_t \\odot \\tanh(c_t).\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Intuition: (i_t) decides how much new information (g_t) to write, (f_t) decides how much of the old cell (c_{t-1}) to keep, (o_t) decides how much of the updated cell to expose through (h_t).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21e8264-8bef-4002-af8e-fb022891468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb643927-6944-4785-ac3a-935d1f08b17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 4]),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000]], requires_grad=True),\n",
       " torch.Size([20]),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2g = nn.Linear(n_embd, 4 * hidden_size, bias=True)\n",
    "torch.nn.init.constant_(x2g.weight, 0.500)\n",
    "torch.nn.init.zeros_(x2g.bias)\n",
    "x2g.weight.size(), x2g.weight, x2g.bias.size(), x2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cd4aed3-b539-488f-a4ea-0f081ebc100b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 5]),\n",
       " Parameter containing:\n",
       " tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500]], requires_grad=True),\n",
       " torch.Size([20]),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2g = nn.Linear(hidden_size, 4 * hidden_size, bias=True)\n",
    "torch.nn.init.constant_(h2g.weight, 0.250)\n",
    "torch.nn.init.zeros_(h2g.bias)\n",
    "h2g.weight.size(), h2g.weight, h2g.bias.size(), h2g.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea925e-09b9-423c-994c-28bb2061765d",
   "metadata": {},
   "source": [
    "since first pass, incoming weight (h_t) are seroed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09c99f-ab91-4dcb-8f0b-295c3f2a30a2",
   "metadata": {},
   "source": [
    "first pass (future will loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f7b252-dae3-4243-8b6c-ec16a292c1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "        [1.1111, 1.1111, 1.1111, 1.1111]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = x[:, 0, :]\n",
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0083fbeb-d96c-4643-ac4e-44ddd0ac852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_t = torch.zeros(B_batch, hidden_size) \n",
    "h_t = torch.zeros(B_batch, hidden_size) \n",
    "c_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c513c4b-9e62-411c-9ba8-8d8b3b3d2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev, c_prev = h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59708dfc-3e0c-4110-ae16-6b178b18cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 20]),\n",
       " tensor([[2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222,\n",
       "          2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222,\n",
       "          2.2222, 2.2222],\n",
       "         [2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222,\n",
       "          2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222, 2.2222,\n",
       "          2.2222, 2.2222]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gi = x2g(x_0)\n",
    "gi.size(), gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f3b72c5-5547-4605-b0ca-0a1cc9cc0c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 20]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh = h2g(h_prev)\n",
    "gh.size(), gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58799445-c5d7-49a8-9314-58feefba9e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gi + gh\n",
    "i_t, f_t, g_t, o_t = g.chunk(4, dim=-1)\n",
    "\n",
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e66698d-437d-4594-b81c-a7acf090d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_t tensor([[2.2222, 2.2222, 2.2222, 2.2222, 2.2222],\n",
      "        [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>) torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9022, 0.9022, 0.9022, 0.9022, 0.9022],\n",
       "        [0.9022, 0.9022, 0.9022, 0.9022, 0.9022]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('i_t', i_t, i_t.size())\n",
    "i_t = torch.sigmoid(i_t)\n",
    "i_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c14f6950-7d12-466e-a9e9-91245f4d9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_t tensor([[2.2222, 2.2222, 2.2222, 2.2222, 2.2222],\n",
      "        [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>) torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9022, 0.9022, 0.9022, 0.9022, 0.9022],\n",
       "        [0.9022, 0.9022, 0.9022, 0.9022, 0.9022]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('f_t', f_t, f_t.size())\n",
    "f_t = torch.sigmoid(f_t)\n",
    "f_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c142258c-745c-4222-8093-3f80c3291e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_t tensor([[2.2222, 2.2222, 2.2222, 2.2222, 2.2222],\n",
      "        [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>) torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9768, 0.9768, 0.9768, 0.9768, 0.9768],\n",
       "        [0.9768, 0.9768, 0.9768, 0.9768, 0.9768]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('g_t', g_t, g_t.size())\n",
    "g_t = torch.tanh(g_t)\n",
    "g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c152a49-94dd-4d2b-a5b2-a2ac522a9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_t tensor([[2.2222, 2.2222, 2.2222, 2.2222, 2.2222],\n",
      "        [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>) torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9022, 0.9022, 0.9022, 0.9022, 0.9022],\n",
       "        [0.9022, 0.9022, 0.9022, 0.9022, 0.9022]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('o_t', o_t, o_t.size())\n",
    "o_t = torch.sigmoid(o_t)\n",
    "o_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a3613db-8171-4b5d-927c-e213399d2fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.8813, 0.8813, 0.8813, 0.8813, 0.8813],\n",
       "         [0.8813, 0.8813, 0.8813, 0.8813, 0.8813]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_t = (f_t * c_prev) + (i_t * g_t)\n",
    "c_t.size(), c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "729c70bb-abd9-462b-acae-98229d69b8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.7071, 0.7071, 0.7071, 0.7071, 0.7071],\n",
       "         [0.7071, 0.7071, 0.7071, 0.7071, 0.7071]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_t_tanh = torch.tanh(c_t)\n",
    "c_t_tanh.size(), c_t_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99d66f20-4f07-4ca8-b586-e9d82bca89db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
       "         [0.6379, 0.6379, 0.6379, 0.6379, 0.6379]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t = o_t * c_t_tanh\n",
    "\n",
    "h_t.size(), h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088318f-4aa6-47cc-a3c5-3e633b517129",
   "metadata": {},
   "source": [
    "## now do it recursively for the rest of the batch size\n",
    "\n",
    "first we'll need to keep track of h_t for each loop for training, so let's start collecting them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5712a754-aaaf-411f-8465-8c9c69569ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]],\n",
       " \n",
       "         [[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = []\n",
    "hs.append(h_t.unsqueeze(1))\n",
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4124348-ff19-4342-bb51-4df571ef4c30",
   "metadata": {},
   "source": [
    "start at 1 since we did the \"0\" pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c0be513-11d4-4856-94cd-665d63b3d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 1\n",
      "tensor([[1.7892, 1.7892, 1.7892, 1.7892, 1.7892],\n",
      "        [1.7205, 1.7205, 1.7205, 1.7205, 1.7205]], grad_fn=<AddBackward0>) tensor([[0.9017, 0.9017, 0.9017, 0.9017, 0.9017],\n",
      "        [0.8644, 0.8644, 0.8644, 0.8644, 0.8644]], grad_fn=<MulBackward0>)\n",
      "t: 2\n",
      "tensor([[2.6213, 2.6213, 2.6213, 2.6213, 2.6213],\n",
      "        [2.6214, 2.6214, 2.6214, 2.6214, 2.6214]], grad_fn=<AddBackward0>) tensor([[0.9324, 0.9324, 0.9324, 0.9324, 0.9324],\n",
      "        [0.9544, 0.9544, 0.9544, 0.9544, 0.9544]], grad_fn=<MulBackward0>)\n",
      "t: 3\n",
      "tensor([[3.5008, 3.5008, 3.5008, 3.5008, 3.5008],\n",
      "        [3.4190, 3.4190, 3.4190, 3.4190, 3.4190]], grad_fn=<AddBackward0>) tensor([[0.9656, 0.9656, 0.9656, 0.9656, 0.9656],\n",
      "        [0.9438, 0.9438, 0.9438, 0.9438, 0.9438]], grad_fn=<MulBackward0>)\n",
      "t: 4\n",
      "tensor([[4.3574, 4.3574, 4.3574, 4.3574, 4.3574],\n",
      "        [4.2744, 4.2744, 4.2744, 4.2744, 4.2744]], grad_fn=<AddBackward0>) tensor([[0.9683, 0.9683, 0.9683, 0.9683, 0.9683],\n",
      "        [0.9674, 0.9674, 0.9674, 0.9674, 0.9674]], grad_fn=<MulBackward0>)\n",
      "t: 5\n",
      "tensor([[5.1878, 5.1878, 5.1878, 5.1878, 5.1878],\n",
      "        [5.1071, 5.1071, 5.1071, 5.1071, 5.1071]], grad_fn=<AddBackward0>) tensor([[0.9686, 0.9686, 0.9686, 0.9686, 0.9686],\n",
      "        [0.9686, 0.9686, 0.9686, 0.9686, 0.9686]], grad_fn=<MulBackward0>)\n",
      "t: 6\n",
      "tensor([[5.9922, 5.9922, 5.9922, 5.9922, 5.9922],\n",
      "        [5.9141, 5.9141, 5.9141, 5.9141, 5.9141]], grad_fn=<AddBackward0>) tensor([[0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
      "        [0.9687, 0.9687, 0.9687, 0.9687, 0.9687]], grad_fn=<MulBackward0>)\n",
      "t: 7\n",
      "tensor([[6.7715, 6.7715, 6.7715, 6.7715, 6.7715],\n",
      "        [6.5398, 6.5398, 6.5398, 6.5398, 6.5398]], grad_fn=<AddBackward0>) tensor([[0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
      "        [0.9467, 0.9467, 0.9467, 0.9467, 0.9467]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(1,T):\n",
    "    x_t = x[:, t, :]\n",
    "    h_prev, c_prev = h_t, c_t\n",
    "    gi = x2g(x_t)\n",
    "    gh = h2g(h_prev)\n",
    "    g = gi + gh\n",
    "    i_t, f_t, g_t, o_t = g.chunk(4, dim=-1)\n",
    "    i_t = torch.sigmoid(i_t)\n",
    "    f_t = torch.sigmoid(f_t)\n",
    "    g_t = torch.tanh(g_t)\n",
    "    o_t = torch.sigmoid(o_t)\n",
    "\n",
    "    c_t = (f_t * c_prev) + (i_t * g_t)\n",
    "    \n",
    "    c_t_tanh = torch.tanh(c_t)\n",
    "    h_t = o_t * c_t_tanh\n",
    "\n",
    "    print(f't: {t}')\n",
    "    print(c_t, h_t)\n",
    "    hs.append(h_t.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de5f7269-332d-48e5-ba64-d36de54ac446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]],\n",
       " \n",
       "         [[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9017, 0.9017, 0.9017, 0.9017, 0.9017]],\n",
       " \n",
       "         [[0.8644, 0.8644, 0.8644, 0.8644, 0.8644]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9324, 0.9324, 0.9324, 0.9324, 0.9324]],\n",
       " \n",
       "         [[0.9544, 0.9544, 0.9544, 0.9544, 0.9544]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9656, 0.9656, 0.9656, 0.9656, 0.9656]],\n",
       " \n",
       "         [[0.9438, 0.9438, 0.9438, 0.9438, 0.9438]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9683, 0.9683, 0.9683, 0.9683, 0.9683]],\n",
       " \n",
       "         [[0.9674, 0.9674, 0.9674, 0.9674, 0.9674]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9686, 0.9686, 0.9686, 0.9686, 0.9686]],\n",
       " \n",
       "         [[0.9686, 0.9686, 0.9686, 0.9686, 0.9686]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       " \n",
       "         [[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       " \n",
       "         [[0.9467, 0.9467, 0.9467, 0.9467, 0.9467]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583b860-2977-49cb-8945-9c60eeb3d479",
   "metadata": {},
   "source": [
    "Combine out recurring inputs into the 2 different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5214c260-55b7-4c85-a1b2-97aa5fb09603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
       "         [0.9017, 0.9017, 0.9017, 0.9017, 0.9017],\n",
       "         [0.9324, 0.9324, 0.9324, 0.9324, 0.9324],\n",
       "         [0.9656, 0.9656, 0.9656, 0.9656, 0.9656],\n",
       "         [0.9683, 0.9683, 0.9683, 0.9683, 0.9683],\n",
       "         [0.9686, 0.9686, 0.9686, 0.9686, 0.9686],\n",
       "         [0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
       "         [0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       "\n",
       "        [[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
       "         [0.8644, 0.8644, 0.8644, 0.8644, 0.8644],\n",
       "         [0.9544, 0.9544, 0.9544, 0.9544, 0.9544],\n",
       "         [0.9438, 0.9438, 0.9438, 0.9438, 0.9438],\n",
       "         [0.9674, 0.9674, 0.9674, 0.9674, 0.9674],\n",
       "         [0.9686, 0.9686, 0.9686, 0.9686, 0.9686],\n",
       "         [0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
       "         [0.9467, 0.9467, 0.9467, 0.9467, 0.9467]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat(hs, dim=1) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c77db-2d10-454f-b512-92ac5b024e61",
   "metadata": {},
   "source": [
    "**Dropout** to fight vanishing / exploding gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14428ec8-69e9-4605-a6fa-eb1012337be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 5]),\n",
       " tensor([[[0.7088, 0.7088, 0.7088, 0.0000, 0.7088],\n",
       "          [0.0000, 1.0018, 0.0000, 1.0018, 1.0018],\n",
       "          [1.0360, 1.0360, 1.0360, 1.0360, 1.0360],\n",
       "          [1.0728, 1.0728, 1.0728, 1.0728, 1.0728],\n",
       "          [0.0000, 1.0759, 1.0759, 1.0759, 1.0759],\n",
       "          [1.0763, 0.0000, 1.0763, 1.0763, 1.0763],\n",
       "          [1.0763, 1.0763, 1.0763, 1.0763, 1.0763],\n",
       "          [1.0764, 0.0000, 1.0764, 1.0764, 1.0764]],\n",
       " \n",
       "         [[0.7088, 0.7088, 0.7088, 0.7088, 0.0000],\n",
       "          [0.9604, 0.9604, 0.9604, 0.9604, 0.0000],\n",
       "          [1.0604, 1.0604, 1.0604, 1.0604, 1.0604],\n",
       "          [1.0487, 1.0487, 1.0487, 1.0487, 1.0487],\n",
       "          [1.0749, 1.0749, 1.0749, 1.0749, 1.0749],\n",
       "          [1.0762, 1.0762, 0.0000, 1.0762, 1.0762],\n",
       "          [1.0763, 1.0763, 1.0763, 1.0763, 1.0763],\n",
       "          [0.0000, 1.0519, 1.0519, 1.0519, 1.0519]]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22593c65-be72-436f-9e1c-8620c22c04ab",
   "metadata": {},
   "source": [
    "**Output Head**\n",
    "projects down from the hiden size to the vocab for us to get logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27e76d90-e130-4e4f-a221-18ee7461876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 5]),\n",
       " Parameter containing:\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]], requires_grad=True))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "torch.nn.init.ones_(lm_head.weight)\n",
    "lm_head.weight.size(), lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19b23a27-073d-499e-a5d3-5d1cc5d42f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 36]),\n",
       " tensor([[[2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352],\n",
       "          [3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "           3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "           3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "           3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "           3.0055, 3.0055, 3.0055, 3.0055],\n",
       "          [5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "           5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "           5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "           5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "           5.1801, 5.1801, 5.1801, 5.1801],\n",
       "          [5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "           5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "           5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "           5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "           5.3642, 5.3642, 5.3642, 5.3642],\n",
       "          [4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "           4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "           4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "           4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "           4.3035, 4.3035, 4.3035, 4.3035],\n",
       "          [4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "           4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "           4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "           4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "           4.3051, 4.3051, 4.3051, 4.3051],\n",
       "          [5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817],\n",
       "          [4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "           4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "           4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "           4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "           4.3054, 4.3054, 4.3054, 4.3054]],\n",
       " \n",
       "         [[2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "           2.8352, 2.8352, 2.8352, 2.8352],\n",
       "          [3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "           3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "           3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "           3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "           3.8417, 3.8417, 3.8417, 3.8417],\n",
       "          [5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "           5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "           5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "           5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "           5.3021, 5.3021, 5.3021, 5.3021],\n",
       "          [5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "           5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "           5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "           5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "           5.2433, 5.2433, 5.2433, 5.2433],\n",
       "          [5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "           5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "           5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "           5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "           5.3744, 5.3744, 5.3744, 5.3744],\n",
       "          [4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "           4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "           4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "           4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "           4.3049, 4.3049, 4.3049, 4.3049],\n",
       "          [5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "           5.3817, 5.3817, 5.3817, 5.3817],\n",
       "          [4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "           4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "           4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "           4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "           4.2077, 4.2077, 4.2077, 4.2077]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(x)\n",
    "\n",
    "logits.shape, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c01b9-d09b-4708-bd9e-3aceeeb9cb18",
   "metadata": {},
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8423d81b-3ceb-44a0-b8dd-7b7ffe5cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dce85cc-5c7e-47bf-8f0e-e23b7f6aa337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]),\n",
       " tensor([15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_flat = y.view(-1)\n",
    "y_flat.shape, y_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03a2daf1-b8cb-4660-9b46-c60d6c95ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 36]),\n",
       " tensor([[2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352],\n",
       "         [3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "          3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "          3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055,\n",
       "          3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055, 3.0055],\n",
       "         [5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "          5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "          5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801,\n",
       "          5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801, 5.1801],\n",
       "         [5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "          5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "          5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642,\n",
       "          5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642, 5.3642],\n",
       "         [4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "          4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "          4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035,\n",
       "          4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035, 4.3035],\n",
       "         [4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "          4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "          4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051,\n",
       "          4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051, 4.3051],\n",
       "         [5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817],\n",
       "         [4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "          4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "          4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054,\n",
       "          4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054, 4.3054],\n",
       "         [2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352,\n",
       "          2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352, 2.8352],\n",
       "         [3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "          3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "          3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417,\n",
       "          3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417, 3.8417],\n",
       "         [5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "          5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "          5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021,\n",
       "          5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021, 5.3021],\n",
       "         [5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "          5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "          5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433,\n",
       "          5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433, 5.2433],\n",
       "         [5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "          5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "          5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744,\n",
       "          5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744, 5.3744],\n",
       "         [4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "          4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "          4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049,\n",
       "          4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049, 4.3049],\n",
       "         [5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817,\n",
       "          5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817, 5.3817],\n",
       "         [4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "          4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "          4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077,\n",
       "          4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077, 4.2077]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.view(-1, logits.size(-1))\n",
    "logits_flat.shape, logits_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b287d1b-c82f-4f51-bb49-7a542ddd3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), tensor(3.5835, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits_flat, y_flat)\n",
    "loss.shape, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587d633-a3ed-49e3-a90a-9c505b079665",
   "metadata": {},
   "source": [
    "## Back Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0455dc7a-fab4-4844-bf37-2ac311226907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head.zero_grad()\n",
    "h2g.zero_grad()\n",
    "x2g.zero_grad()\n",
    "wte.zero_grad()\n",
    "\n",
    "\n",
    "# validate gradients\n",
    "lm_head.weight.grad, wte.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0b7acd2-55bc-4fe6-9c41-1ddc0ee05eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "119fa3fb-0e8c-4db3-9df8-4a1b361279d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0445, -0.1086, -0.1084, -0.1061, -0.1077],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.1099, -0.1082, -0.1081, -0.1057, -0.1074],\n",
       "         [-0.0374, -0.0357, -0.0355, -0.0332,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0864, -0.0847, -0.0846, -0.0822, -0.0396],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446,  0.0244, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446, -0.0429,  0.0245, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0889, -0.0872, -0.0871, -0.0404, -0.0864],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0436, -0.1092, -0.1090, -0.1067, -0.1083],\n",
       "         [-0.0446, -0.0429, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446,  0.0244, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227, -0.0383,  0.0245, -0.0358, -0.0374],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252]]),\n",
       " tensor([[7.3524e-10, 7.3524e-10, 7.3524e-10, 7.3524e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.7511e-09, 2.7511e-09, 2.7511e-09, 2.7511e-09],\n",
       "         [1.1821e-09, 1.1821e-09, 1.1821e-09, 1.1821e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.7115e-09, 4.7115e-09, 4.7115e-09, 1.6863e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.8562e-09, 4.8562e-09, 4.8562e-09, 4.8562e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [9.6790e-10, 9.6790e-10, 9.6790e-10, 9.6790e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.4469e-09, 2.4469e-09, 2.4469e-09, 2.4469e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0804e-09, 3.9082e-09, 3.9082e-09, 3.9082e-09],\n",
       "         [2.5517e-09, 0.0000e+00, 2.5517e-09, 2.5517e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [8.9751e-10, 8.9751e-10, 8.9751e-10, 8.9751e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.4477e-09, 2.4477e-09, 0.0000e+00, 2.4477e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [3.5355e-09, 3.5355e-09, 3.5355e-09, 3.5355e-09]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head.weight.grad, wte.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb42053-0ac1-4a63-bc94-926a8f22eeb8",
   "metadata": {},
   "source": [
    "**Gradient clipping**\n",
    "While gradient clipping helps with exploding gradients,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df8265d8-4b8f-4ca5-807d-98c8cb5192c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0445, -0.1086, -0.1084, -0.1061, -0.1077],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.1099, -0.1082, -0.1081, -0.1057, -0.1074],\n",
       "         [-0.0374, -0.0357, -0.0355, -0.0332,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0864, -0.0847, -0.0846, -0.0822, -0.0396],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446,  0.0244, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446, -0.0429,  0.0245, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0889, -0.0872, -0.0871, -0.0404, -0.0864],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0436, -0.1092, -0.1090, -0.1067, -0.1083],\n",
       "         [-0.0446, -0.0429, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [-0.0446,  0.0244, -0.0428, -0.0404, -0.0421],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227, -0.0383,  0.0245, -0.0358, -0.0374],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252],\n",
       "         [ 0.0227,  0.0244,  0.0245,  0.0269,  0.0252]]),\n",
       " tensor([[7.3524e-10, 7.3524e-10, 7.3524e-10, 7.3524e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.7511e-09, 2.7511e-09, 2.7511e-09, 2.7511e-09],\n",
       "         [1.1821e-09, 1.1821e-09, 1.1821e-09, 1.1821e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.7115e-09, 4.7115e-09, 4.7115e-09, 1.6863e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.8562e-09, 4.8562e-09, 4.8562e-09, 4.8562e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [9.6790e-10, 9.6790e-10, 9.6790e-10, 9.6790e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.4469e-09, 2.4469e-09, 2.4469e-09, 2.4469e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0804e-09, 3.9082e-09, 3.9082e-09, 3.9082e-09],\n",
       "         [2.5517e-09, 0.0000e+00, 2.5517e-09, 2.5517e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [8.9751e-10, 8.9751e-10, 8.9751e-10, 8.9751e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.4477e-09, 2.4477e-09, 0.0000e+00, 2.4477e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [3.5355e-09, 3.5355e-09, 3.5355e-09, 3.5355e-09]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.utils.clip_grad_norm_(lm_head.parameters(), 1.0)\n",
    "nn.utils.clip_grad_norm_(h2g.parameters(), 1.0)\n",
    "nn.utils.clip_grad_norm_(x2g.parameters(), 1.0)\n",
    "nn.utils.clip_grad_norm_(wte.parameters(), 1.0)\n",
    "lm_head.weight.grad, wte.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8564d2f-34d0-4526-80b7-69337e2a7549",
   "metadata": {},
   "source": [
    "## Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2b11f32-0c10-480d-9690-402132913444",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Huge learning rate to emphasize\n",
    "learning_rate = 5.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c59984-6d36-4e78-b7fc-cf4623294915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.2226, 1.5428, 1.5422, 1.5303, 1.5386],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.5497, 1.5412, 1.5405, 1.5287, 1.5370],\n",
       "        [1.1868, 1.1783, 1.1777, 1.1658, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.4320, 1.4235, 1.4228, 1.4109, 1.1978],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.2231, 0.8782, 1.2139, 1.2020, 1.2104],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.2230, 1.2145, 0.8776, 1.2020, 1.2103],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.4446, 1.4361, 1.4354, 1.2020, 1.4319],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.2181, 1.5458, 1.5452, 1.5333, 1.5416],\n",
       "        [1.2231, 1.2146, 1.2139, 1.2020, 1.2104],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [1.2230, 0.8782, 1.2139, 1.2020, 1.2104],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 1.1913, 0.8776, 1.1788, 1.1871],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740],\n",
       "        [0.8867, 0.8782, 0.8776, 0.8657, 0.8740]], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lm_head.weight -= learning_rate * lm_head.weight.grad\n",
    "lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44461eb7-82b4-4383-afab-ef1c18203289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-7.2200e-09, -8.3450e-09, -7.2256e-09, -6.3360e-09, -4.3217e-09,\n",
       "         -1.1036e-09, -1.4571e-09, -1.1113e-09, -1.4614e-09, -9.4995e-10,\n",
       "         -3.3119e-09, -3.7435e-09, -3.3135e-09, -2.7777e-09, -1.8734e-09,\n",
       "         -4.0437e-08, -4.7523e-08, -4.6181e-08, -4.8216e-08, -4.2015e-08],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    h2g.weight -= learning_rate * h2g.weight.grad\n",
    "    h2g.bias -= learning_rate * h2g.bias.grad\n",
    "h2g.weight, h2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24badddf-11c7-4c52-a31b-d7ef1912c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-7.2200e-09, -8.3450e-09, -7.2256e-09, -6.3360e-09, -4.3217e-09,\n",
       "         -1.1036e-09, -1.4571e-09, -1.1113e-09, -1.4614e-09, -9.4995e-10,\n",
       "         -3.3119e-09, -3.7435e-09, -3.3135e-09, -2.7777e-09, -1.8734e-09,\n",
       "         -4.0437e-08, -4.7523e-08, -4.6181e-08, -4.8216e-08, -4.2015e-08],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x2g.weight -= learning_rate * x2g.weight.grad\n",
    "    x2g.bias -= learning_rate * x2g.bias.grad\n",
    "x2g.weight, x2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97f58304-61da-46de-862d-b7e807e61d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    wte.weight -= learning_rate * wte.weight.grad\n",
    "wte.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ff10f-f64f-4801-b9ea-c40e15816684",
   "metadata": {},
   "source": [
    "## Forward Pass with Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00925f19-c83a-4549-b4ca-94f92ad301f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[35, 15, 32,  9,  5, 20, 30, 15],\n",
       "         [11,  9,  6, 20,  5,  0, 13, 21]]),\n",
       " tensor([[15, 32,  9,  5, 20, 30, 15, 11],\n",
       "         [ 9,  6, 20,  5,  0, 13, 21,  0]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = tok_for_training[:-1].view(B, T)\n",
    "x_2, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c68d0-cf29-431d-85d2-0d0276e55c70",
   "metadata": {},
   "source": [
    "## Input projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff392189-88e9-46a8-9ce1-b1aacad80e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4]),\n",
       " tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wte(x_2)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522598e4-600b-49ac-aca8-5ce33a9f8c8e",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f0c0ab4-a8da-4b22-ba93-92070f03527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [0.0000, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 0.0000, 0.0000, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111]],\n",
       "\n",
       "        [[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 0.0000, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 0.0000],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 0.0000, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5ddc4-503d-4a8c-8635-2a6b26d4750e",
   "metadata": {},
   "source": [
    "**Recurrent Block** Collapsed Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6d785-4282-431d-829b-e3ade8326816",
   "metadata": {},
   "source": [
    "h_t, c_t still resets to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a88d1ae-b4e8-46e0-9538-f94589005472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_t = torch.zeros(B_batch, hidden_size) \n",
    "h_t = torch.zeros(B_batch, hidden_size) \n",
    "hs = []\n",
    "c_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8ce97ab-1e58-4c12-b558-f9c216b341e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "tensor([[0.8813, 0.8813, 0.8813, 0.8813, 0.8813],\n",
      "        [0.8813, 0.8813, 0.8813, 0.8813, 0.8813]], grad_fn=<AddBackward0>) tensor([[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
      "        [0.6379, 0.6379, 0.6379, 0.6379, 0.6379]], grad_fn=<MulBackward0>)\n",
      "t: 1\n",
      "tensor([[1.7892, 1.7892, 1.7892, 1.7892, 1.7892],\n",
      "        [1.7205, 1.7205, 1.7205, 1.7205, 1.7205]], grad_fn=<AddBackward0>) tensor([[0.9017, 0.9017, 0.9017, 0.9017, 0.9017],\n",
      "        [0.8644, 0.8644, 0.8644, 0.8644, 0.8644]], grad_fn=<MulBackward0>)\n",
      "t: 2\n",
      "tensor([[2.6213, 2.6213, 2.6213, 2.6213, 2.6213],\n",
      "        [2.5489, 2.5489, 2.5489, 2.5489, 2.5489]], grad_fn=<AddBackward0>) tensor([[0.9324, 0.9324, 0.9324, 0.9324, 0.9324],\n",
      "        [0.9283, 0.9283, 0.9283, 0.9283, 0.9283]], grad_fn=<MulBackward0>)\n",
      "t: 3\n",
      "tensor([[3.2654, 3.2654, 3.2654, 3.2654, 3.2654],\n",
      "        [3.4301, 3.4301, 3.4301, 3.4301, 3.4301]], grad_fn=<AddBackward0>) tensor([[0.9043, 0.9043, 0.9043, 0.9043, 0.9043],\n",
      "        [0.9651, 0.9651, 0.9651, 0.9651, 0.9651]], grad_fn=<MulBackward0>)\n",
      "t: 4\n",
      "tensor([[4.1188, 4.1188, 4.1188, 4.1188, 4.1188],\n",
      "        [4.2889, 4.2889, 4.2889, 4.2889, 4.2889]], grad_fn=<AddBackward0>) tensor([[0.9657, 0.9657, 0.9657, 0.9657, 0.9657],\n",
      "        [0.9682, 0.9682, 0.9682, 0.9682, 0.9682]], grad_fn=<MulBackward0>)\n",
      "t: 5\n",
      "tensor([[4.9561, 4.9561, 4.9561, 4.9561, 4.9561],\n",
      "        [5.0010, 5.0010, 5.0010, 5.0010, 5.0010]], grad_fn=<AddBackward0>) tensor([[0.9685, 0.9685, 0.9685, 0.9685, 0.9685],\n",
      "        [0.9466, 0.9466, 0.9466, 0.9466, 0.9466]], grad_fn=<MulBackward0>)\n",
      "t: 6\n",
      "tensor([[5.7677, 5.7677, 5.7677, 5.7677, 5.7677],\n",
      "        [5.8061, 5.8061, 5.8061, 5.8061, 5.8061]], grad_fn=<AddBackward0>) tensor([[0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
      "        [0.9679, 0.9679, 0.9679, 0.9679, 0.9679]], grad_fn=<MulBackward0>)\n",
      "t: 7\n",
      "tensor([[6.5540, 6.5540, 6.5540, 6.5540, 6.5540],\n",
      "        [6.5910, 6.5910, 6.5910, 6.5910, 6.5910]], grad_fn=<AddBackward0>) tensor([[0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
      "        [0.9687, 0.9687, 0.9687, 0.9687, 0.9687]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    x_t = x[:, t, :]\n",
    "    h_prev, c_prev = h_t, c_t\n",
    "    gi = x2g(x_t)\n",
    "    gh = h2g(h_prev)\n",
    "    g = gi + gh\n",
    "    i_t, f_t, g_t, o_t = g.chunk(4, dim=-1)\n",
    "    i_t = torch.sigmoid(i_t)\n",
    "    f_t = torch.sigmoid(f_t)\n",
    "    g_t = torch.tanh(g_t)\n",
    "    o_t = torch.sigmoid(o_t)\n",
    "\n",
    "    c_t = (f_t * c_prev) + (i_t * g_t)\n",
    "    \n",
    "    c_t_tanh = torch.tanh(c_t)\n",
    "    h_t = o_t * c_t_tanh\n",
    "\n",
    "    print(f't: {t}')\n",
    "    print(c_t, h_t)\n",
    "    hs.append(h_t.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3232e9b6-7205-4e1a-982b-f67d9352d0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]],\n",
       " \n",
       "         [[0.6379, 0.6379, 0.6379, 0.6379, 0.6379]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9017, 0.9017, 0.9017, 0.9017, 0.9017]],\n",
       " \n",
       "         [[0.8644, 0.8644, 0.8644, 0.8644, 0.8644]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9324, 0.9324, 0.9324, 0.9324, 0.9324]],\n",
       " \n",
       "         [[0.9283, 0.9283, 0.9283, 0.9283, 0.9283]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9043, 0.9043, 0.9043, 0.9043, 0.9043]],\n",
       " \n",
       "         [[0.9651, 0.9651, 0.9651, 0.9651, 0.9651]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9657, 0.9657, 0.9657, 0.9657, 0.9657]],\n",
       " \n",
       "         [[0.9682, 0.9682, 0.9682, 0.9682, 0.9682]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9685, 0.9685, 0.9685, 0.9685, 0.9685]],\n",
       " \n",
       "         [[0.9466, 0.9466, 0.9466, 0.9466, 0.9466]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       " \n",
       "         [[0.9679, 0.9679, 0.9679, 0.9679, 0.9679]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       " \n",
       "         [[0.9687, 0.9687, 0.9687, 0.9687, 0.9687]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5de2c-9cfb-4292-a7e9-4e45c2e2e913",
   "metadata": {},
   "source": [
    "combine weights back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80e35fdc-c488-4dac-87a1-dcc12a0e2abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 5]),\n",
       " tensor([[[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
       "          [0.9017, 0.9017, 0.9017, 0.9017, 0.9017],\n",
       "          [0.9324, 0.9324, 0.9324, 0.9324, 0.9324],\n",
       "          [0.9043, 0.9043, 0.9043, 0.9043, 0.9043],\n",
       "          [0.9657, 0.9657, 0.9657, 0.9657, 0.9657],\n",
       "          [0.9685, 0.9685, 0.9685, 0.9685, 0.9685],\n",
       "          [0.9687, 0.9687, 0.9687, 0.9687, 0.9687],\n",
       "          [0.9687, 0.9687, 0.9687, 0.9687, 0.9687]],\n",
       " \n",
       "         [[0.6379, 0.6379, 0.6379, 0.6379, 0.6379],\n",
       "          [0.8644, 0.8644, 0.8644, 0.8644, 0.8644],\n",
       "          [0.9283, 0.9283, 0.9283, 0.9283, 0.9283],\n",
       "          [0.9651, 0.9651, 0.9651, 0.9651, 0.9651],\n",
       "          [0.9682, 0.9682, 0.9682, 0.9682, 0.9682],\n",
       "          [0.9466, 0.9466, 0.9466, 0.9466, 0.9466],\n",
       "          [0.9679, 0.9679, 0.9679, 0.9679, 0.9679],\n",
       "          [0.9687, 0.9687, 0.9687, 0.9687, 0.9687]]], grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat(hs, dim=1) \n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c53d-c55b-4940-852d-79498d489245",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f4b0ebe-0dab-458c-bba1-0d0617a9b294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7088, 0.7088, 0.7088, 0.7088, 0.7088],\n",
       "         [1.0018, 1.0018, 1.0018, 1.0018, 1.0018],\n",
       "         [0.0000, 1.0360, 1.0360, 1.0360, 1.0360],\n",
       "         [1.0048, 1.0048, 1.0048, 1.0048, 1.0048],\n",
       "         [1.0730, 1.0730, 1.0730, 1.0730, 1.0730],\n",
       "         [1.0761, 1.0761, 1.0761, 1.0761, 1.0761],\n",
       "         [1.0763, 1.0763, 1.0763, 1.0763, 1.0763],\n",
       "         [1.0764, 1.0764, 1.0764, 1.0764, 1.0764]],\n",
       "\n",
       "        [[0.7088, 0.7088, 0.7088, 0.7088, 0.7088],\n",
       "         [0.9604, 0.9604, 0.9604, 0.9604, 0.9604],\n",
       "         [0.0000, 1.0315, 1.0315, 1.0315, 1.0315],\n",
       "         [1.0724, 1.0724, 1.0724, 1.0724, 1.0724],\n",
       "         [0.0000, 1.0758, 1.0758, 1.0758, 1.0758],\n",
       "         [1.0518, 1.0518, 1.0518, 1.0518, 1.0518],\n",
       "         [1.0754, 1.0754, 1.0754, 1.0754, 1.0754],\n",
       "         [1.0763, 1.0763, 1.0763, 1.0763, 1.0763]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1e47d-27d3-4039-8ea1-208d5fc30f29",
   "metadata": {},
   "source": [
    "**Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c2c2354-3b5c-4490-ac42-fd8474355857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 36]),\n",
       " tensor([[[5.2286, 3.1061, 3.1061, 3.1061, 3.1061, 5.4557, 3.9571, 3.1061,\n",
       "           3.1061, 4.8816, 3.1061, 4.0598, 3.1061, 4.0597, 3.1061, 4.9262,\n",
       "           3.1061, 3.1061, 3.1061, 3.1061, 5.2338, 4.2982, 3.1061, 3.1061,\n",
       "           3.1061, 3.1061, 3.1061, 3.1061, 3.1061, 3.1061, 4.0597, 3.1061,\n",
       "           3.7719, 3.1061, 3.1061, 3.1061],\n",
       "          [7.3902, 4.3903, 4.3903, 4.3903, 4.3903, 7.7112, 5.5930, 4.3903,\n",
       "           4.3903, 6.8997, 4.3903, 5.7382, 4.3903, 5.7380, 4.3903, 6.9628,\n",
       "           4.3903, 4.3903, 4.3903, 4.3903, 7.3975, 6.0751, 4.3903, 4.3903,\n",
       "           4.3903, 4.3903, 4.3903, 4.3903, 4.3903, 4.3903, 5.7381, 4.3903,\n",
       "           5.3312, 4.3903, 4.3903, 4.3903],\n",
       "          [6.3757, 3.6214, 3.6214, 3.6214, 3.6214, 6.3688, 4.5543, 3.6214,\n",
       "           3.6214, 5.6516, 3.6214, 4.6669, 3.6214, 4.6667, 3.6214, 5.7038,\n",
       "           3.6214, 3.6214, 3.6214, 3.6214, 6.3880, 5.0153, 3.6214, 3.6214,\n",
       "           3.6214, 3.6214, 3.6214, 3.6214, 3.6214, 3.6214, 4.6668, 3.6214,\n",
       "           4.5945, 3.6214, 3.6214, 3.6214],\n",
       "          [7.4117, 4.4030, 4.4030, 4.4030, 4.4030, 7.7337, 5.6093, 4.4030,\n",
       "           4.4030, 6.9198, 4.4030, 5.7549, 4.4030, 5.7547, 4.4030, 6.9831,\n",
       "           4.4030, 4.4030, 4.4030, 4.4030, 7.4191, 6.0928, 4.4030, 4.4030,\n",
       "           4.4030, 4.4030, 4.4030, 4.4030, 4.4030, 4.4030, 5.7548, 4.4030,\n",
       "           5.3467, 4.4030, 4.4030, 4.4030],\n",
       "          [7.9149, 4.7020, 4.7020, 4.7020, 4.7020, 8.2587, 5.9901, 4.7020,\n",
       "           4.7020, 7.3896, 4.7020, 6.1456, 4.7020, 6.1454, 4.7020, 7.4572,\n",
       "           4.7020, 4.7020, 4.7020, 4.7020, 7.9228, 6.5065, 4.7020, 4.7020,\n",
       "           4.7020, 4.7020, 4.7020, 4.7020, 4.7020, 4.7020, 6.1455, 4.7020,\n",
       "           5.7097, 4.7020, 4.7020, 4.7020],\n",
       "          [7.9381, 4.7158, 4.7158, 4.7158, 4.7158, 8.2830, 6.0077, 4.7158,\n",
       "           4.7158, 7.4113, 4.7158, 6.1637, 4.7158, 6.1635, 4.7158, 7.4791,\n",
       "           4.7158, 4.7158, 4.7158, 4.7158, 7.9460, 6.5256, 4.7158, 4.7158,\n",
       "           4.7158, 4.7158, 4.7158, 4.7158, 4.7158, 4.7158, 6.1635, 4.7158,\n",
       "           5.7265, 4.7158, 4.7158, 4.7158],\n",
       "          [7.9396, 4.7167, 4.7167, 4.7167, 4.7167, 8.2845, 6.0088, 4.7167,\n",
       "           4.7167, 7.4127, 4.7167, 6.1648, 4.7167, 6.1646, 4.7167, 7.4805,\n",
       "           4.7167, 4.7167, 4.7167, 4.7167, 7.9476, 6.5268, 4.7167, 4.7167,\n",
       "           4.7167, 4.7167, 4.7167, 4.7167, 4.7167, 4.7167, 6.1647, 4.7167,\n",
       "           5.7276, 4.7167, 4.7167, 4.7167],\n",
       "          [7.9398, 4.7168, 4.7168, 4.7168, 4.7168, 8.2847, 6.0090, 4.7168,\n",
       "           4.7168, 7.4129, 4.7168, 6.1650, 4.7168, 6.1648, 4.7168, 7.4807,\n",
       "           4.7168, 4.7168, 4.7168, 4.7168, 7.9477, 6.5270, 4.7168, 4.7168,\n",
       "           4.7168, 4.7168, 4.7168, 4.7168, 4.7168, 4.7168, 6.1649, 4.7168,\n",
       "           5.7277, 4.7168, 4.7168, 4.7168]],\n",
       " \n",
       "         [[5.2286, 3.1061, 3.1061, 3.1061, 3.1061, 5.4557, 3.9571, 3.1061,\n",
       "           3.1061, 4.8816, 3.1061, 4.0598, 3.1061, 4.0597, 3.1061, 4.9262,\n",
       "           3.1061, 3.1061, 3.1061, 3.1061, 5.2338, 4.2982, 3.1061, 3.1061,\n",
       "           3.1061, 3.1061, 3.1061, 3.1061, 3.1061, 3.1061, 4.0597, 3.1061,\n",
       "           3.7719, 3.1061, 3.1061, 3.1061],\n",
       "          [7.0846, 4.2087, 4.2087, 4.2087, 4.2087, 7.3924, 5.3617, 4.2087,\n",
       "           4.2087, 6.6144, 4.2087, 5.5009, 4.2087, 5.5008, 4.2087, 6.6749,\n",
       "           4.2087, 4.2087, 4.2087, 4.2087, 7.0917, 5.8240, 4.2087, 4.2087,\n",
       "           4.2087, 4.2087, 4.2087, 4.2087, 4.2087, 4.2087, 5.5008, 4.2087,\n",
       "           5.1108, 4.2087, 4.2087, 4.2087],\n",
       "          [6.3477, 3.6056, 3.6056, 3.6056, 3.6056, 6.3409, 4.5343, 3.6056,\n",
       "           3.6056, 5.6268, 3.6056, 4.6464, 3.6056, 4.6463, 3.6056, 5.6788,\n",
       "           3.6056, 3.6056, 3.6056, 3.6056, 6.3600, 4.9933, 3.6056, 3.6056,\n",
       "           3.6056, 3.6056, 3.6056, 3.6056, 3.6056, 3.6056, 4.6463, 3.6056,\n",
       "           4.5743, 3.6056, 3.6056, 3.6056],\n",
       "          [7.9104, 4.6993, 4.6993, 4.6993, 4.6993, 8.2541, 5.9867, 4.6993,\n",
       "           4.6993, 7.3854, 4.6993, 6.1421, 4.6993, 6.1420, 4.6993, 7.4529,\n",
       "           4.6993, 4.6993, 4.6993, 4.6993, 7.9183, 6.5028, 4.6993, 4.6993,\n",
       "           4.6993, 4.6993, 4.6993, 4.6993, 4.6993, 4.6993, 6.1420, 4.6993,\n",
       "           5.7065, 4.6993, 4.6993, 4.6993],\n",
       "          [6.6205, 3.7605, 3.7605, 3.7605, 3.7605, 6.6134, 4.7291, 3.7605,\n",
       "           3.7605, 5.8685, 3.7605, 4.8460, 3.7605, 4.8459, 3.7605, 5.9228,\n",
       "           3.7605, 3.7605, 3.7605, 3.7605, 6.6333, 5.2079, 3.7605, 3.7605,\n",
       "           3.7605, 3.7605, 3.7605, 3.7605, 3.7605, 3.7605, 4.8460, 3.7605,\n",
       "           4.7709, 3.7605, 3.7605, 3.7605],\n",
       "          [7.7586, 4.6091, 4.6091, 4.6091, 4.6091, 8.0956, 5.8718, 4.6091,\n",
       "           4.6091, 7.2437, 4.6091, 6.0243, 4.6091, 6.0241, 4.6091, 7.3099,\n",
       "           4.6091, 4.6091, 4.6091, 4.6091, 7.7663, 6.3780, 4.6091, 4.6091,\n",
       "           4.6091, 4.6091, 4.6091, 4.6091, 4.6091, 4.6091, 6.0241, 4.6091,\n",
       "           5.5970, 4.6091, 4.6091, 4.6091],\n",
       "          [7.9328, 4.7126, 4.7126, 4.7126, 4.7126, 8.2774, 6.0036, 4.7126,\n",
       "           4.7126, 7.4063, 4.7126, 6.1595, 4.7126, 6.1593, 4.7126, 7.4740,\n",
       "           4.7126, 4.7126, 4.7126, 4.7126, 7.9407, 6.5212, 4.7126, 4.7126,\n",
       "           4.7126, 4.7126, 4.7126, 4.7126, 4.7126, 4.7126, 6.1594, 4.7126,\n",
       "           5.7226, 4.7126, 4.7126, 4.7126],\n",
       "          [7.9396, 4.7166, 4.7166, 4.7166, 4.7166, 8.2845, 6.0088, 4.7166,\n",
       "           4.7166, 7.4126, 4.7166, 6.1648, 4.7166, 6.1646, 4.7166, 7.4804,\n",
       "           4.7166, 4.7166, 4.7166, 4.7166, 7.9475, 6.5268, 4.7166, 4.7166,\n",
       "           4.7166, 4.7166, 4.7166, 4.7166, 4.7166, 4.7166, 6.1647, 4.7166,\n",
       "           5.7275, 4.7166, 4.7166, 4.7166]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(x)\n",
    "logits.shape, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed1cae-6af9-4211-82b1-8930196c48c3",
   "metadata": {},
   "source": [
    "### Updated Loss calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c101fbc-97fc-4dc2-b99e-1cff59d22f5d",
   "metadata": {},
   "source": [
    "Now we'll calculate the updated loss.  Our first pass's loss was 3.5835. Since we're passing through the same example and used a fairly high learning rate we should see a significant improvement with just 1 learning pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a12e542-dda9-4cb4-9611-bcb157515806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5835, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2c2eb99-d188-4de7-a4ee-27917e3cec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) tensor(2.6797, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_flat = y.view(-1)\n",
    "logits_flat = logits.view(-1, logits.size(-1))\n",
    "updated_loss = F.cross_entropy(logits_flat, y_flat)\n",
    "print(updated_loss.shape, updated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53363221-ba7b-49f8-8f6a-88c6db647277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 round of training resulted in an loss improvment of 0.9038'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'1 round of training resulted in an loss improvment of {loss.item() - updated_loss.item():.4f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56dfda-a142-40b3-b66f-60cb6cae0a8e",
   "metadata": {},
   "source": [
    "# SUCCESS!\n",
    "Our training improved the loss by about **~25%** (amount may vary since we didn't set a seed). There are flaws with this, mainly passing the same example through a second time, but this helps show the fundamentals of what learning does inside a GPT-2 style model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4ccfa-7d97-4c63-b46b-8ac6a44a5dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
