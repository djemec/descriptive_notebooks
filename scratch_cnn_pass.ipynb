{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b439199d-f470-4918-8a28-a7c72775e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d30ceaa-666b-4bf4-b580-720471dac1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBPETokenizer:\n",
    "    def __init__(self, num_merges=5, eot_token='<|endoftext|>'):\n",
    "        self.num_merges = num_merges\n",
    "        self.eot_token = eot_token\n",
    "        self.eot_id = None\n",
    "        self.merges = []\n",
    "        self.pair_ranks = {}\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "\n",
    "    def _add_token(self, tok):\n",
    "        if tok in self.vocab:\n",
    "            return self.vocab[tok]\n",
    "        i = len(self.vocab)\n",
    "        self.vocab[tok] = i\n",
    "        self.id_to_token[i] = tok\n",
    "        return i\n",
    "\n",
    "    def _get_bigrams(self, seq):\n",
    "        for i in range(len(seq) - 1):\n",
    "            yield (seq[i], seq[i + 1])\n",
    "\n",
    "    def _merge_once(self, seq, pair):\n",
    "        a, b = pair\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            if i < len(seq) - 1 and seq[i] == a and seq[i + 1] == b:\n",
    "                out.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                out.append(seq[i])\n",
    "                i += 1\n",
    "        return out\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # corpus: list[str]\n",
    "        text = ''.join(corpus).lower()\n",
    "        seq = list(text)\n",
    "        merges = []\n",
    "        for _ in range(self.num_merges):\n",
    "            counts = Counter(self._get_bigrams(seq))\n",
    "            if not counts: break\n",
    "            best_pair, _ = counts.most_common(1)[0]\n",
    "            merges.append(best_pair)\n",
    "            seq = self._merge_once(seq, best_pair)\n",
    "        self.merges = merges\n",
    "        self.pair_ranks = {p: i for i, p in enumerate(self.merges)}\n",
    "\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "        for ch in sorted(set(text)):\n",
    "            self._add_token(ch)\n",
    "        for a, b in self.merges:\n",
    "            self._add_token(a + b)\n",
    "        self.eot_id = self._add_token(self.eot_token)\n",
    "\n",
    "    def encode(self, text, force_last_eot=True):\n",
    "        # treat literal eot marker as special; remove it from content\n",
    "        if self.eot_token in text:\n",
    "            text = text.replace(self.eot_token, '')\n",
    "        seq = list(text)\n",
    "\n",
    "        # make sure all seen base chars exist\n",
    "        for ch in set(seq):\n",
    "            if ch not in self.vocab:\n",
    "                self._add_token(ch)\n",
    "\n",
    "        # greedy BPE using learned pair ranks\n",
    "        if self.merges:\n",
    "            while True:\n",
    "                best_pair, best_rank = None, None\n",
    "                for p in self._get_bigrams(seq):\n",
    "                    r = self.pair_ranks.get(p)\n",
    "                    if r is not None and (best_rank is None or r < best_rank):\n",
    "                        best_pair, best_rank = p, r\n",
    "                if best_pair is None:\n",
    "                    break\n",
    "                seq = self._merge_once(seq, best_pair)\n",
    "\n",
    "        # ensure all tokens in seq exist in vocab (e.g., if new chars appeared)\n",
    "        for tok in seq:\n",
    "            if tok not in self.vocab:\n",
    "                self._add_token(tok)\n",
    "\n",
    "        ids = [self.vocab[tok] for tok in seq]\n",
    "\n",
    "        # FORCE: append EOT id if not already last\n",
    "        if force_last_eot:\n",
    "            if not ids or ids[-1] != self.eot_id:\n",
    "                ids.append(self.eot_id)\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # drop trailing EOT if present\n",
    "        if ids and self.eot_id is not None and ids[-1] == self.eot_id:\n",
    "            ids = ids[:-1]\n",
    "        toks = [self.id_to_token[i] for i in ids]\n",
    "        return ''.join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b23350-048b-430b-adbc-1da85b188314",
   "metadata": {},
   "outputs": [],
   "source": [
    "twinkle_twinkle = r'CCGGAAG,FFEEDDC,GGFFEED,GGFFEED,CCGGAAG,FFEEDDC'\n",
    "hot_cross_buns = r'EDC,EDC,CCCC,DDDD,EDC'\n",
    "happy_birthday = r'GGAGCB,GGAGDC,GGGECBA,FFECDC'\n",
    "mary_had_a_little_lamb = r'EDCDEEE,DDD,EGG,EDCDEEE,EDD,EDC'\n",
    "frere_jacques = r'CDEC,CDEC,EFG,EFG,GAGFEC,GAGFEC,CGC,CGC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8593940b-000d-4c9d-bce4-88e58a7afc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 'd'), ('c', ','), ('g', 'g'), ('f', 'e'), ('a', 'g'), ('c', 'c')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = SimpleBPETokenizer(num_merges=6)\n",
    "examples = [twinkle_twinkle,hot_cross_buns, happy_birthday, mary_had_a_little_lamb, frere_jacques]\n",
    "tok.train(examples)\n",
    "tok.merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd56cd75-cf05-4a58-ae36-e3b824407b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'ed': 8,\n",
       " 'c,': 9,\n",
       " 'gg': 10,\n",
       " 'fe': 11,\n",
       " 'ag': 12,\n",
       " 'cc': 13,\n",
       " '<|endoftext|>': 14}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264e16ed-fa4d-4d91-ab0e-83f61076717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tok.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ccacbd-6e9d-4103-8f9c-fe9c55e1630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131,\n",
       " tensor([14, 13, 10,  1, 12,  0,  6, 11,  8,  4,  9, 10,  6, 11,  8,  0, 10,  6,\n",
       "         11,  8,  0, 13, 10,  1, 12,  0,  6, 11,  8,  4,  3, 14, 14,  8,  9,  8,\n",
       "          9, 13,  3,  9,  4,  4,  4,  4,  0,  8,  3, 14, 14, 10, 12,  3,  2,  0,\n",
       "         10, 12,  4,  9, 10,  7,  5,  3,  2,  1,  0,  6, 11,  3,  4,  3, 14, 14,\n",
       "          8,  3,  4,  5,  5,  5,  0,  4,  4,  4,  0,  5, 10,  0,  8,  3,  4,  5,\n",
       "          5,  5,  0,  8,  4,  0,  8,  3, 14, 14,  3,  4,  5,  9,  3,  4,  5,  9,\n",
       "          5,  6,  7,  0,  5,  6,  7,  0,  7, 12, 11,  9,  7, 12, 11,  9,  3,  7,\n",
       "          9,  3,  7,  3, 14]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eot = tok.eot_id\n",
    "tokens = []\n",
    "for example in examples:\n",
    "    tokens.extend([eot])\n",
    "    tokens.extend(tok.encode(example.lower()))\n",
    "all_tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "len_tok = len(all_tokens)\n",
    "len_tok, all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30752508-5037-4f49-afb0-13d001d449aa",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa3f48c-2151-4474-8df3-0fdc9c3265e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dExplicit(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=0, bias=False):\n",
    "        super().__init__()\n",
    "        kh, kw = kernel_size\n",
    "        sh, sw = stride\n",
    "        ph, pw = padding\n",
    "        self.in_ch, self.out_ch = in_ch, out_ch\n",
    "        self.kh, self.kw, self.sh, self.sw, self.ph, self.pw = kh, kw, sh, sw, ph, pw\n",
    "        self.weight = nn.Parameter(torch.empty(out_ch, in_ch, kh, kw))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_ch)) if bias else None\n",
    "        nn.init.kaiming_normal_(self.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        cols = F.unfold(x, (self.kh, self.kw), padding=(self.ph, self.pw), stride=(self.sh, self.sw))\n",
    "        Wflat = self.weight.view(self.out_ch, -1)\n",
    "        out = Wflat @ cols\n",
    "        if self.bias is not None: out = out + self.bias.view(1, -1, 1)\n",
    "        Hout = (H + 2*self.ph - self.kh)//self.sh + 1\n",
    "        Wout = (W + 2*self.pw - self.kw)//self.sw + 1\n",
    "        return out.view(N, self.out_ch, Hout, Wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f458e027-694e-4113-a39b-879ce73bfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1xk(in_ch, out_ch, k=3, stride_w=1, pad_w=None):\n",
    "    if pad_w is None: pad_w = k//2\n",
    "    return Conv2dExplicit(in_ch, out_ch, kernel_size=(1,k), stride=(1,stride_w), padding=(0,pad_w), bias=False)\n",
    "    \n",
    "class SingleConvBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv1xk(channels, channels, k=3, stride_w=1) # 1x3 stride 1\n",
    "        self.bn_a = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = conv1xk(channels, channels, k=3, stride_w=2) # 1x3 stride 2\n",
    "        self.bn_b = nn.BatchNorm2d(channels)\n",
    "        self.convRes = conv1xk(channels, channels, k=1, stride_w=2, pad_w=0) #1x1 stride 2\n",
    "        # c and g are ReLU and residual connection inside forward\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn_a(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn_b(out)\n",
    "        identity = self.convRes(x)\n",
    "        out = out + identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3482f3a5-5260-478d-8a13-c892a0413adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyTextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=6):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.n_embd = vocab_size, n_embd\n",
    "        self.wte = nn.Embedding(vocab_size, n_embd)\n",
    "        self.block = SingleConvBlock(n_embd)\n",
    "        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "        nn.init.normal_(self.lm_head.weight, 0, 0.02)\n",
    "    def forward(self, X, Y=None):\n",
    "        B, T = X.shape\n",
    "        x = self.wte(X)\n",
    "        x = x.permute(0,2,1).unsqueeze(2)\n",
    "        x = self.block(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.squeeze(2).permute(0,2,1)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if Y is not None:\n",
    "            T_out = logits.size(1)\n",
    "            Y = Y[:, :T_out]\n",
    "            loss = F.cross_entropy(logits.reshape(B*T_out, self.vocab_size), Y.reshape(B*T_out))\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8915ddc1-c8bd-4f28-a783-8a4cfae114e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(all_tokens, cur_position, b, t, len_tok=len_tok):\n",
    "        \n",
    "    window = b * t + 1\n",
    "    cur_position += random.randint(1, t) \n",
    "    if cur_position >= len_tok:\n",
    "        cur_position -= len_tok\n",
    "    end = cur_position + window\n",
    "    if end <= len_tok:\n",
    "        tok_for_training = all_tokens[cur_position:end]\n",
    "    else:\n",
    "        restart = end-len_tok\n",
    "        tok_for_training = torch.cat((all_tokens[cur_position:],all_tokens[:restart]), dim=0)\n",
    "        position = end % len_tok\n",
    "\n",
    "    x = tok_for_training[:-1].view(b, t)\n",
    "    y = tok_for_training[t::t].view(b, 1)\n",
    "\n",
    "    return  x, y, cur_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3656f-9c12-4792-8d37-6cfb2a508142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f939f5a6-eae1-4c9b-83da-9776f70a3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "B_batch, T_context, n_embd = 2, 8, 6\n",
    "cur_position = 0\n",
    "learning_rate = 1e-4\n",
    "training_steps = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e37b3fb-49c2-4bbc-9880-931c90f4dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyTextCNN(vocab_size=vocab_size, n_embd=n_embd)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da281fc-c765-4d67-b8ec-be86e288be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 456\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total, trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116e69e9-64fd-454a-aae5-eb64d4e1370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "max_lr= 1e-2\n",
    "scheduler = OneCycleLR(\n",
    "    opt, max_lr=max_lr, total_steps=training_steps,\n",
    "    pct_start=0.1, anneal_strategy='cos', cycle_momentum=False\n",
    ")\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fe76ce-83fa-4781-9797-1d2399c2cef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.7314\n",
      "step 1000 loss 2.3915\n",
      "step 2000 loss 1.7371\n",
      "step 3000 loss 0.5785\n",
      "step 4000 loss 1.6708\n",
      "step 5000 loss 2.0368\n",
      "step 6000 loss 1.6624\n",
      "step 7000 loss 0.9160\n",
      "step 8000 loss 2.3188\n",
      "step 9000 loss 0.5319\n",
      "step 10000 loss 0.2991\n",
      "step 11000 loss 0.9256\n",
      "step 12000 loss 0.2787\n",
      "step 13000 loss 0.1429\n",
      "step 14000 loss 0.5148\n",
      "step 15000 loss 0.3242\n",
      "step 16000 loss 0.1570\n",
      "step 17000 loss 1.6638\n",
      "step 18000 loss 0.0027\n",
      "step 19000 loss 0.7556\n",
      "step 20000 loss 0.2918\n",
      "step 21000 loss 0.1316\n",
      "step 22000 loss 0.4115\n",
      "step 23000 loss 0.2037\n",
      "step 24000 loss 0.1675\n",
      "step 25000 loss 0.1974\n",
      "step 26000 loss 0.0472\n",
      "step 27000 loss 0.0260\n",
      "step 28000 loss 0.2235\n",
      "step 29000 loss 0.2035\n",
      "step 30000 loss 0.1105\n",
      "step 31000 loss 0.4434\n",
      "step 32000 loss 0.4879\n",
      "step 33000 loss 0.2683\n",
      "step 34000 loss 0.3531\n",
      "step 35000 loss 0.1668\n",
      "step 36000 loss 0.2157\n",
      "step 37000 loss 0.4550\n",
      "step 38000 loss 0.0481\n",
      "step 39000 loss 0.3595\n",
      "step 40000 loss 0.1199\n",
      "step 41000 loss 0.0751\n",
      "step 42000 loss 0.2390\n",
      "step 43000 loss 0.2263\n",
      "step 44000 loss 0.0146\n",
      "step 45000 loss 0.2946\n",
      "step 46000 loss 0.0304\n",
      "step 47000 loss 0.0723\n",
      "step 48000 loss 0.1560\n",
      "step 49000 loss 0.0041\n",
      "step 50000 loss 0.2173\n",
      "step 51000 loss 0.1029\n",
      "step 52000 loss 0.5048\n",
      "step 53000 loss 0.1292\n",
      "step 54000 loss 0.1464\n",
      "step 55000 loss 0.8008\n",
      "step 56000 loss 0.0509\n",
      "step 57000 loss 0.2075\n",
      "step 58000 loss 0.0981\n",
      "step 59000 loss 0.1889\n",
      "step 60000 loss 0.0264\n",
      "step 61000 loss 0.0993\n",
      "step 62000 loss 0.2649\n",
      "step 63000 loss 0.4251\n",
      "step 64000 loss 0.3288\n",
      "step 65000 loss 0.1603\n",
      "step 66000 loss 0.1688\n",
      "step 67000 loss 0.1403\n",
      "step 68000 loss 0.1148\n",
      "step 69000 loss 0.1464\n",
      "step 70000 loss 0.1441\n",
      "step 71000 loss 0.2028\n",
      "step 72000 loss 0.0647\n",
      "step 73000 loss 0.2116\n",
      "step 74000 loss 0.1684\n",
      "step 75000 loss 0.0805\n",
      "step 76000 loss 0.1584\n",
      "step 77000 loss 0.0324\n",
      "step 78000 loss 0.0335\n",
      "step 79000 loss 0.1781\n",
      "step 80000 loss 0.0144\n",
      "step 81000 loss 0.0485\n",
      "step 82000 loss 0.0563\n",
      "step 83000 loss 0.0838\n",
      "step 84000 loss 0.0162\n",
      "step 85000 loss 0.0120\n",
      "step 86000 loss 0.0055\n",
      "step 87000 loss 0.0405\n",
      "step 88000 loss 0.0069\n",
      "step 89000 loss 0.0286\n",
      "step 90000 loss 0.0073\n",
      "step 91000 loss 0.0041\n",
      "step 92000 loss 0.0343\n",
      "step 93000 loss 0.0092\n",
      "step 94000 loss 0.0425\n",
      "step 95000 loss 0.0800\n",
      "step 96000 loss 0.0061\n",
      "step 97000 loss 0.0376\n",
      "step 98000 loss 0.0303\n",
      "step 99000 loss 0.0186\n"
     ]
    }
   ],
   "source": [
    "for step in range(training_steps):\n",
    "    x, y, cur_position = get_batch(all_tokens, cur_position, B_batch, T_context, len_tok)\n",
    "    logits, loss = model(x, y)\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    lossi.append(loss.item())\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step {step} loss {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27fe484-8a30-472b-ae75-7f1a44b2528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x149f31a90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54acca2-d165-43a0-8038-8652cd7153a5",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df3f05b3-75b9-42f7-a5e2-eceb553cb345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 13, 10,  1, 12,  0,  6, 11,  8,  4,  9, 10,  6, 11,  8,  0, 10])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_position = 0\n",
    "tok_for_training = all_tokens[current_position:current_position + B_batch*T_context +1 ]\n",
    "tok_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee5c6c75-1050-4f52-897f-bb9c4073477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8]),\n",
       " tensor([[14, 13, 10,  1, 12,  0,  6, 11],\n",
       "         [ 8,  4,  9, 10,  6, 11,  8,  0]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tok_for_training[:-1].view(B_batch, T_context)\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f813686-9923-4402-8b00-7067e0c82e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]),\n",
       " tensor([[ 8],\n",
       "         [10]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tok_for_training[T_context::T_context].view(B_batch, 1)\n",
    "y.size(), y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837e586-05e2-4ad2-a95d-7449bb26c87e",
   "metadata": {},
   "source": [
    "#### Input Layer - Embedding Projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e66f3a61-7b3c-4737-bb09-78b1ed508583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 6]),\n",
       " tensor([[[-0.3538, -1.7279, -0.2208, -0.1422, -0.2779,  0.0971],\n",
       "          [ 0.1340, -1.9109,  0.8488,  0.3037,  0.5439,  1.2975],\n",
       "          [-0.1212, -1.0493,  1.3160, -0.6819, -0.1818,  0.3020],\n",
       "          [ 0.9336,  0.3767, -1.2423, -0.2280, -0.2998,  0.3576],\n",
       "          [-0.8815,  0.6066, -0.0922,  1.2983,  1.0177,  0.3613],\n",
       "          [-1.1437, -0.3150, -1.0516, -0.0303, -0.0545,  0.2966],\n",
       "          [-0.2197, -0.6855,  0.0498, -0.2830,  2.2638, -0.2275],\n",
       "          [ 0.6324,  0.3081, -0.6845, -0.1421,  1.0040, -0.5515]],\n",
       " \n",
       "         [[ 0.0611,  0.7857,  0.4427,  0.1858, -0.2440,  1.0037],\n",
       "          [ 0.2021,  0.2374,  0.0892, -1.0603, -0.0903,  0.5618],\n",
       "          [ 0.0355,  0.6805, -0.4257,  0.7430,  0.8040,  1.0051],\n",
       "          [-0.1212, -1.0493,  1.3160, -0.6819, -0.1818,  0.3020],\n",
       "          [-0.2197, -0.6855,  0.0498, -0.2830,  2.2638, -0.2275],\n",
       "          [ 0.6324,  0.3081, -0.6845, -0.1421,  1.0040, -0.5515],\n",
       "          [ 0.0611,  0.7857,  0.4427,  0.1858, -0.2440,  1.0037],\n",
       "          [-1.1437, -0.3150, -1.0516, -0.0303, -0.0545,  0.2966]]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.wte(x)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202dc41-30d8-41e9-a304-3f80ea18f6a2",
   "metadata": {},
   "source": [
    "#### Input Layer - Add Dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6af48031-ccf4-4482-a80e-aa445b6fccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6, 1, 8]),\n",
       " tensor([[[[-0.3538,  0.1340, -0.1212,  0.9336, -0.8815, -1.1437, -0.2197,\n",
       "             0.6324]],\n",
       " \n",
       "          [[-1.7279, -1.9109, -1.0493,  0.3767,  0.6066, -0.3150, -0.6855,\n",
       "             0.3081]],\n",
       " \n",
       "          [[-0.2208,  0.8488,  1.3160, -1.2423, -0.0922, -1.0516,  0.0498,\n",
       "            -0.6845]],\n",
       " \n",
       "          [[-0.1422,  0.3037, -0.6819, -0.2280,  1.2983, -0.0303, -0.2830,\n",
       "            -0.1421]],\n",
       " \n",
       "          [[-0.2779,  0.5439, -0.1818, -0.2998,  1.0177, -0.0545,  2.2638,\n",
       "             1.0040]],\n",
       " \n",
       "          [[ 0.0971,  1.2975,  0.3020,  0.3576,  0.3613,  0.2966, -0.2275,\n",
       "            -0.5515]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0611,  0.2021,  0.0355, -0.1212, -0.2197,  0.6324,  0.0611,\n",
       "            -1.1437]],\n",
       " \n",
       "          [[ 0.7857,  0.2374,  0.6805, -1.0493, -0.6855,  0.3081,  0.7857,\n",
       "            -0.3150]],\n",
       " \n",
       "          [[ 0.4427,  0.0892, -0.4257,  1.3160,  0.0498, -0.6845,  0.4427,\n",
       "            -1.0516]],\n",
       " \n",
       "          [[ 0.1858, -1.0603,  0.7430, -0.6819, -0.2830, -0.1421,  0.1858,\n",
       "            -0.0303]],\n",
       " \n",
       "          [[-0.2440, -0.0903,  0.8040, -0.1818,  2.2638,  1.0040, -0.2440,\n",
       "            -0.0545]],\n",
       " \n",
       "          [[ 1.0037,  0.5618,  1.0051,  0.3020, -0.2275, -0.5515,  1.0037,\n",
       "             0.2966]]]], grad_fn=<UnsqueezeBackward0>))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(0,2,1).unsqueeze(2)\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b320f2-aac0-4aee-ae9b-bbbc8e362656",
   "metadata": {},
   "source": [
    "### Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f734d46b-0f32-4c97-86df-96a4b5141b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5438, -1.8343,  0.7778,  1.1903,  0.6596, -0.4334, -0.2239,\n",
       "            1.3149]],\n",
       "\n",
       "         [[ 1.3532,  0.0383, -2.2688,  2.1619, -0.0755,  0.2142, -1.4898,\n",
       "           -1.4063]],\n",
       "\n",
       "         [[ 2.6253,  2.1959,  1.5959, -1.4981, -1.4970,  0.5298, -1.6367,\n",
       "           -0.1397]],\n",
       "\n",
       "         [[-1.7402,  0.4375,  1.8362, -0.4476, -0.0293, -1.0450, -0.1744,\n",
       "            0.0190]],\n",
       "\n",
       "         [[ 1.3656,  0.5332, -2.7385, -1.5942,  1.3431,  1.1098, -1.0376,\n",
       "            0.2761]],\n",
       "\n",
       "         [[-1.5111, -1.7708, -0.6487,  1.7748,  0.3640,  1.7602, -0.3405,\n",
       "           -0.5390]]],\n",
       "\n",
       "\n",
       "        [[[-0.9065, -0.3760,  0.0365, -1.6030,  1.2263,  1.1063, -1.2582,\n",
       "            1.4567]],\n",
       "\n",
       "         [[-0.1590,  0.1067,  0.1788, -1.5672,  0.0867, -0.8862, -0.4605,\n",
       "            0.5962]],\n",
       "\n",
       "         [[ 0.4418,  0.2572,  0.7289,  2.2856, -0.2720,  0.2183, -0.3050,\n",
       "            0.0085]],\n",
       "\n",
       "         [[ 0.6363, -0.7065, -0.8836, -0.0517,  0.5558,  0.1195,  0.7595,\n",
       "           -1.0517]],\n",
       "\n",
       "         [[-0.3509, -0.9530,  0.4408,  1.0982, -2.9236,  0.7130,  1.0847,\n",
       "            0.3771]],\n",
       "\n",
       "         [[ 1.0454,  1.1433,  0.4341,  0.2476,  0.4495, -0.3478,  0.4273,\n",
       "            0.8235]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.block.conv1(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6eb0390-1bff-425f-b7d4-3898a874e56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8087, -0.9507,  0.3257,  0.5273,  0.2680, -0.2662, -0.1638,\n",
       "            0.5882]],\n",
       "\n",
       "         [[ 0.5618,  0.0563, -0.8307,  0.8728,  0.0125,  0.1239, -0.5312,\n",
       "           -0.4991]],\n",
       "\n",
       "         [[ 0.5243,  0.3487,  0.1034, -1.1616, -1.1611, -0.3325, -1.2183,\n",
       "           -0.6062]],\n",
       "\n",
       "         [[-0.7522,  0.4143,  1.1635, -0.0598,  0.1643, -0.3798,  0.0865,\n",
       "            0.1902]],\n",
       "\n",
       "         [[ 0.4589,  0.1833, -0.9000, -0.5211,  0.4515,  0.3743, -0.3368,\n",
       "            0.0982]],\n",
       "\n",
       "         [[-1.3687, -1.5202, -0.8655,  0.5485, -0.2746,  0.5400, -0.6857,\n",
       "           -0.8015]]],\n",
       "\n",
       "\n",
       "        [[[-0.4973, -0.2381, -0.0365, -0.8377,  0.5449,  0.4862, -0.6692,\n",
       "            0.6575]],\n",
       "\n",
       "         [[-0.0196,  0.0826,  0.1103, -0.5610,  0.0749, -0.2992, -0.1355,\n",
       "            0.2708]],\n",
       "\n",
       "         [[-0.3684, -0.4439, -0.2511,  0.3854, -0.6603, -0.4598, -0.6738,\n",
       "           -0.5456]],\n",
       "\n",
       "         [[ 0.5208, -0.1985, -0.2933,  0.1523,  0.4777,  0.2440,  0.5868,\n",
       "           -0.3833]],\n",
       "\n",
       "         [[-0.1094, -0.3088,  0.1527,  0.3704, -0.9613,  0.2429,  0.3659,\n",
       "            0.1316]],\n",
       "\n",
       "         [[ 0.1229,  0.1800, -0.2338, -0.3425, -0.2248, -0.6900, -0.2377,\n",
       "           -0.0066]]]], grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.block.bn_a(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21cdf9df-7e02-4cd9-9639-a28e6cce40f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.3257, 0.5273, 0.2680, 0.0000, 0.0000, 0.5882]],\n",
       "\n",
       "         [[0.5618, 0.0563, 0.0000, 0.8728, 0.0125, 0.1239, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.5243, 0.3487, 0.1034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.4143, 1.1635, 0.0000, 0.1643, 0.0000, 0.0865, 0.1902]],\n",
       "\n",
       "         [[0.4589, 0.1833, 0.0000, 0.0000, 0.4515, 0.3743, 0.0000, 0.0982]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.5400, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.5449, 0.4862, 0.0000, 0.6575]],\n",
       "\n",
       "         [[0.0000, 0.0826, 0.1103, 0.0000, 0.0749, 0.0000, 0.0000, 0.2708]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.3854, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.5208, 0.0000, 0.0000, 0.1523, 0.4777, 0.2440, 0.5868, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.1527, 0.3704, 0.0000, 0.2429, 0.3659, 0.1316]],\n",
       "\n",
       "         [[0.1229, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.relu(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce1cdc68-4354-4429-bdc8-ed73f85c9e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0205, -0.0948,  0.6327, -0.3263]],\n",
       "\n",
       "         [[-0.1981, -0.5394, -0.2201, -0.1169]],\n",
       "\n",
       "         [[-0.1069, -0.3643,  0.4101,  0.1075]],\n",
       "\n",
       "         [[ 0.0188, -0.0428, -0.8928,  0.4109]],\n",
       "\n",
       "         [[-0.4434, -0.5494, -0.0349, -0.2168]],\n",
       "\n",
       "         [[-0.3652, -0.2399,  0.2695,  0.6908]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1212,  0.0863, -0.2642, -0.2323]],\n",
       "\n",
       "         [[-0.2575,  0.1796, -0.0595, -0.2123]],\n",
       "\n",
       "         [[-0.0642,  0.1111,  0.2721, -0.4824]],\n",
       "\n",
       "         [[-0.1205,  0.0011, -0.1129,  0.3895]],\n",
       "\n",
       "         [[-0.3531, -0.4930, -0.2933, -0.3222]],\n",
       "\n",
       "         [[-0.1048, -0.0677,  0.4173,  0.0026]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.block.conv2(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c52aea3-5bd7-48bc-b512-c0452111bd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0.2974,  -1.7095,  17.9336,  -7.9594]],\n",
       "\n",
       "         [[ -0.6157, -15.3298,  -1.5639,   2.8861]],\n",
       "\n",
       "         [[ -0.2852,  -4.2287,   7.6366,   3.0005]],\n",
       "\n",
       "         [[  1.2572,   0.2816, -13.1710,   7.4617]],\n",
       "\n",
       "         [[ -5.5067, -10.3068,  12.9883,   4.7507]],\n",
       "\n",
       "         [[ -6.8455,  -4.6658,   4.1988,  11.5314]]],\n",
       "\n",
       "\n",
       "        [[[  4.1219,   3.1811,  -6.2829,  -5.4211]],\n",
       "\n",
       "         [[ -3.1777,  15.6672,   5.3587,  -1.2289]],\n",
       "\n",
       "         [[  0.3699,   3.0556,   5.5218,  -6.0378]],\n",
       "\n",
       "         [[ -0.9472,   0.9759,  -0.8272,   7.1241]],\n",
       "\n",
       "         [[ -1.4197,  -7.7539,   1.2889,  -0.0189]],\n",
       "\n",
       "         [[ -2.3136,  -1.6697,   6.7717,  -0.4448]]]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.block.bn_b(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f6d96-59f6-42e4-bce4-8ac74d2e328e",
   "metadata": {},
   "source": [
    "### Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e989466-f658-4b12-bc9e-e855aafdf48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.9052, -5.4700,  0.6940, -4.3136]],\n",
       "\n",
       "         [[-1.4775,  2.0132, -4.6039, -0.8955]],\n",
       "\n",
       "         [[ 2.6279,  1.2826,  2.6689,  7.6903]],\n",
       "\n",
       "         [[-1.3493, -3.0138,  4.9637, -1.9745]],\n",
       "\n",
       "         [[-6.8618, -5.9337,  7.2757,  1.2419]],\n",
       "\n",
       "         [[-0.2063, -2.0876, -1.7645, -6.8481]]],\n",
       "\n",
       "\n",
       "        [[[ 3.7676,  4.1082, -4.3136,  3.7676]],\n",
       "\n",
       "         [[-0.2943, -3.4238, -0.8955, -0.2943]],\n",
       "\n",
       "         [[-1.5818,  1.6430,  7.6903, -1.5818]],\n",
       "\n",
       "         [[-0.1494,  0.7467, -1.9745, -0.1494]],\n",
       "\n",
       "         [[ 3.2147,  5.9827,  1.2419,  3.2147]],\n",
       "\n",
       "         [[ 1.9591,  0.4460, -6.8481,  1.9591]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity = model.block.convRes(x)\n",
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20935cb5-cf02-452f-8d23-ad356ce23ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -6.6077,  -7.1795,  18.6277, -12.2730]],\n",
       "\n",
       "         [[ -2.0932, -13.3166,  -6.1678,   1.9906]],\n",
       "\n",
       "         [[  2.3427,  -2.9461,  10.3055,  10.6908]],\n",
       "\n",
       "         [[ -0.0921,  -2.7322,  -8.2073,   5.4871]],\n",
       "\n",
       "         [[-12.3685, -16.2405,  20.2640,   5.9927]],\n",
       "\n",
       "         [[ -7.0518,  -6.7534,   2.4343,   4.6834]]],\n",
       "\n",
       "\n",
       "        [[[  7.8895,   7.2893, -10.5965,  -1.6535]],\n",
       "\n",
       "         [[ -3.4721,  12.2435,   4.4632,  -1.5233]],\n",
       "\n",
       "         [[ -1.2120,   4.6986,  13.2120,  -7.6196]],\n",
       "\n",
       "         [[ -1.0966,   1.7225,  -2.8017,   6.9748]],\n",
       "\n",
       "         [[  1.7951,  -1.7712,   2.5308,   3.1959]],\n",
       "\n",
       "         [[ -0.3545,  -1.2236,  -0.0763,   1.5143]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = out + identity\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d67f6-aff9-4ffe-ab71-79cb45b72e3c",
   "metadata": {},
   "source": [
    "#### Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "69da947c-f4e5-4dfb-9a7e-162535b7df1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.8581]],\n",
       "\n",
       "         [[-4.8968]],\n",
       "\n",
       "         [[ 5.0982]],\n",
       "\n",
       "         [[-1.3861]],\n",
       "\n",
       "         [[-0.5881]],\n",
       "\n",
       "         [[-1.6719]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7322]],\n",
       "\n",
       "         [[ 2.9278]],\n",
       "\n",
       "         [[ 2.2698]],\n",
       "\n",
       "         [[ 1.1997]],\n",
       "\n",
       "         [[ 1.4376]],\n",
       "\n",
       "         [[-0.0350]]]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.avgPool(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29cdd703-8947-497c-bbdb-a8e1ba9e9ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8581, -4.8968,  5.0982, -1.3861, -0.5881, -1.6719]],\n",
       "\n",
       "        [[ 0.7322,  2.9278,  2.2698,  1.1997,  1.4376, -0.0350]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze(2).permute(0,2,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ff2c382-4012-4ac1-9e13-ab8fc4387b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.4625,   6.4465,   3.7128,   7.7496,   3.9683, -32.9022,   4.0918,\n",
       "          -23.3142,  15.8635,  11.2772, -12.5994, -20.7938,   5.8372,   4.9852,\n",
       "          -30.2750]],\n",
       "\n",
       "        [[  2.9112,   3.1109, -12.4211,   4.5833,  -3.0127,  -6.8175,   5.3184,\n",
       "          -11.4279,  -0.9332,  -7.2218,  12.1359,   4.1800,  -2.6490,  -1.1821,\n",
       "            5.7186]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.lm_head(x)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ceba70-b710-4a26-93c9-cf4ca818cc6c",
   "metadata": {},
   "source": [
    "### Updated Loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "724762b2-2cd2-40b6-ad69-52aaace6fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) tensor(0.0072, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_flat = y.view(-1)\n",
    "logits_flat = logits.view(-1, logits.size(-1))\n",
    "loss = F.cross_entropy(logits_flat, y_flat)\n",
    "print(loss.shape, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30a7ae-a7a2-4669-9541-9ed8f7715948",
   "metadata": {},
   "source": [
    "### Next Token Prediction from Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f039f95a-eb4e-48de-b482-44a99a766f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_for_training = all_tokens[current_position:current_position + B_batch*T_context +1 ]\n",
    "xgen =tok_for_training[:-1].view(B_batch, T_context)\n",
    "max_length = 16\n",
    "num_return_sequences = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e45108bc-6149-4fc1-b2be-7d13aab83a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while xgen.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits, loss = model(xgen[:,-B_batch:]) # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # select a token \n",
    "        xcol = torch.multinomial(probs, 1, generator=sample_rng) # (B, 1)\n",
    "        # append to the sequence\n",
    "        xgen = torch.cat((xgen, xcol), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eaf1f82f-b2c6-4f8b-8b25-63b52235c750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 13, 10,  1, 12,  0,  6, 11, 12,  0, 13,  2,  8, 14, 14,  2],\n",
       "        [ 8,  4,  9, 10,  6, 11,  8,  0,  5,  2,  4,  5, 10,  0,  1,  4]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b927e38f-b579-4aac-a635-670cec238e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: <|endoftext|>ccggaag,ffeag,ccbed<|endoftext|><|endoftext|>b\n",
      "sample 1: eddc,ggffeed,ebdegg,ad\n"
     ]
    }
   ],
   "source": [
    "# print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = xgen[i, :max_length].tolist()\n",
    "    decoded = tok.decode(tokens)\n",
    "    print(f'sample {i}: {decoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "585443fe-ccdd-4c43-8041-36442b4e6304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14, 13, 10, 1, 12, 0, 6, 11, 8, 4, 9, 10, 6, 11, 8, 0, 10],\n",
       " '<|endoftext|>ccggaag,ffeeddc,ggffeed,gg')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_original = tok_for_training[:].tolist()\n",
    "tokens_original, tok.decode(tokens_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935c309-5e6d-4dd8-accb-25ddf724cd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
