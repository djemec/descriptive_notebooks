{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfe8b6e-ca81-4bf0-8cbc-e7503784f06a",
   "metadata": {},
   "source": [
    "# CNN ResNet Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f393843-8889-4c95-9c49-759a8e264095",
   "metadata": {},
   "source": [
    "!!!!!!some info about resnets\n",
    "\n",
    "To help display how the CNNs works, we'll use the first sentence from the [linear algebra wiki page](https://en.wikipedia.org/wiki/Linear_algebra) and [lu decomposition wiki page](https://en.wikipedia.org/wiki/LU_decomposition) as the topic is fitting and it shows us some non-standard patterns.  We'll take on a more simple task to many other notebooks in this repository where we have a few sentences of text and want to predict some other text, in this case the next token. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968de25-053a-45ce-9028-c03e90bdfa7c",
   "metadata": {},
   "source": [
    "## Text Prep/Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2685be2-e06d-4009-97b5-f26a3f61bac4",
   "metadata": {},
   "source": [
    "We'll start with a common preprocessing step of tokenizing the data.  This converts the string text into an array of numbers that can be used during the training loop.  I've built a very subtle byte-pair encoding that has each unique character that appears and the top 5 merges. This keeps our vocab size small and manageable for this example. Typically the vocab size is in the 100K+ range. A great library for this is `tiktoken`. Tokenization simply finds the longest pattern of characters that's in common with what was trained and replaces it with an integer that represents it.  This way we turn the text into a numeric array to simplify computing. import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a6ac3c8-73c9-4b54-b6eb-233b5c405223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4919114e-83f0-4d2a-8a97-c4648da21f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBPETokenizer:\n",
    "    def __init__(self, num_merges=5, eot_token='<|endoftext|>'):\n",
    "        self.num_merges = num_merges\n",
    "        self.eot_token = eot_token\n",
    "        self.eot_id = None\n",
    "        self.merges = []\n",
    "        self.pair_ranks = {}\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "\n",
    "    def _add_token(self, tok):\n",
    "        if tok in self.vocab:\n",
    "            return self.vocab[tok]\n",
    "        i = len(self.vocab)\n",
    "        self.vocab[tok] = i\n",
    "        self.id_to_token[i] = tok\n",
    "        return i\n",
    "\n",
    "    def _get_bigrams(self, seq):\n",
    "        for i in range(len(seq) - 1):\n",
    "            yield (seq[i], seq[i + 1])\n",
    "\n",
    "    def _merge_once(self, seq, pair):\n",
    "        a, b = pair\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            if i < len(seq) - 1 and seq[i] == a and seq[i + 1] == b:\n",
    "                out.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                out.append(seq[i])\n",
    "                i += 1\n",
    "        return out\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # corpus: list[str]\n",
    "        text = ''.join(corpus).lower()\n",
    "        seq = list(text)\n",
    "        merges = []\n",
    "        for _ in range(self.num_merges):\n",
    "            counts = Counter(self._get_bigrams(seq))\n",
    "            if not counts: break\n",
    "            best_pair, _ = counts.most_common(1)[0]\n",
    "            merges.append(best_pair)\n",
    "            seq = self._merge_once(seq, best_pair)\n",
    "        self.merges = merges\n",
    "        self.pair_ranks = {p: i for i, p in enumerate(self.merges)}\n",
    "\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "        for ch in sorted(set(text)):\n",
    "            self._add_token(ch)\n",
    "        for a, b in self.merges:\n",
    "            self._add_token(a + b)\n",
    "        self.eot_id = self._add_token(self.eot_token)\n",
    "\n",
    "    def encode(self, text, force_last_eot=True):\n",
    "        # treat literal eot marker as special; remove it from content\n",
    "        if self.eot_token in text:\n",
    "            text = text.replace(self.eot_token, '')\n",
    "        seq = list(text)\n",
    "\n",
    "        # make sure all seen base chars exist\n",
    "        for ch in set(seq):\n",
    "            if ch not in self.vocab:\n",
    "                self._add_token(ch)\n",
    "\n",
    "        # greedy BPE using learned pair ranks\n",
    "        if self.merges:\n",
    "            while True:\n",
    "                best_pair, best_rank = None, None\n",
    "                for p in self._get_bigrams(seq):\n",
    "                    r = self.pair_ranks.get(p)\n",
    "                    if r is not None and (best_rank is None or r < best_rank):\n",
    "                        best_pair, best_rank = p, r\n",
    "                if best_pair is None:\n",
    "                    break\n",
    "                seq = self._merge_once(seq, best_pair)\n",
    "\n",
    "        # ensure all tokens in seq exist in vocab (e.g., if new chars appeared)\n",
    "        for tok in seq:\n",
    "            if tok not in self.vocab:\n",
    "                self._add_token(tok)\n",
    "\n",
    "        ids = [self.vocab[tok] for tok in seq]\n",
    "\n",
    "        # FORCE: append EOT id if not already last\n",
    "        if force_last_eot:\n",
    "            if not ids or ids[-1] != self.eot_id:\n",
    "                ids.append(self.eot_id)\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # drop trailing EOT if present\n",
    "        if ids and self.eot_id is not None and ids[-1] == self.eot_id:\n",
    "            ids = ids[:-1]\n",
    "        toks = [self.id_to_token[i] for i in ids]\n",
    "        return ''.join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42b8a5b-552e-4e15-abae-3fac8c3602e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_example_1 = r'''Linear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis, a branch of mathematical analysis, may be viewed as the application of linear algebra to function spaces.'''\n",
    "raw_example_2 = r'''In numerical analysis and linear algebra, lower–upper (LU) decomposition or factorization factors a matrix as the product of a lower triangular matrix and an upper triangular matrix (see matrix multiplication and matrix decomposition).'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb02db67-40d1-4a88-95a1-c497e3bfdaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 'a'), ('a', 't'), ('i', 'n'), (' ', 'm'), ('i', 'o')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = SimpleBPETokenizer(num_merges=5)\n",
    "tok.train([raw_example_1,raw_example_2])\n",
    "tok.merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94546825-52f3-4668-bc9c-80bed6d0a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '(': 1,\n",
       " ')': 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " 'a': 5,\n",
       " 'b': 6,\n",
       " 'c': 7,\n",
       " 'd': 8,\n",
       " 'e': 9,\n",
       " 'f': 10,\n",
       " 'g': 11,\n",
       " 'h': 12,\n",
       " 'i': 13,\n",
       " 'j': 14,\n",
       " 'l': 15,\n",
       " 'm': 16,\n",
       " 'n': 17,\n",
       " 'o': 18,\n",
       " 'p': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " '–': 29,\n",
       " ' a': 30,\n",
       " 'at': 31,\n",
       " 'in': 32,\n",
       " ' m': 33,\n",
       " 'io': 34,\n",
       " '<|endoftext|>': 35}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47bae6f-3a84-4677-8b9a-5851a27ccff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tok.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210d0bdb-2e94-4788-8feb-9a445dfaa12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0,  7,\n",
       "         9, 17, 22, 20,  5, 15,  0, 22, 18, 30, 15, 16, 18, 21, 22, 30, 15, 15,\n",
       "        30, 20,  9,  5, 21,  0, 18, 10, 33, 31, 12,  9, 16, 31, 13,  7, 21,  4,\n",
       "         0, 10, 18, 20,  0, 32, 21, 22,  5, 17,  7,  9,  3,  0, 15, 32,  9,  5,\n",
       "        20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0, 10, 23, 17,  8,  5, 16,\n",
       "         9, 17, 22,  5, 15,  0, 32, 33, 18,  8,  9, 20, 17,  0, 19, 20,  9, 21,\n",
       "         9, 17, 22, 31, 34, 17, 21,  0, 18, 10,  0, 11,  9, 18, 16,  9, 22, 20,\n",
       "        27,  3,  0, 32,  7, 15, 23,  8, 32, 11,  0, 10, 18, 20,  0,  8,  9, 10,\n",
       "        32, 32, 11,  0,  6,  5, 21, 13,  7,  0, 18,  6, 14,  9,  7, 22, 21,  0,\n",
       "        21, 23,  7, 12, 30, 21,  0, 15, 32,  9, 21,  3,  0, 19, 15,  5, 17,  9,\n",
       "        21, 30, 17,  8,  0, 20, 18, 22, 31, 34, 17, 21,  4, 30, 15, 21, 18,  3,\n",
       "         0, 10, 23, 17,  7, 22, 34, 17,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,\n",
       "         3, 30,  0,  6, 20,  5, 17,  7, 12,  0, 18, 10, 33, 31, 12,  9, 16, 31,\n",
       "        13,  7,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,  3, 33,  5, 27,  0,  6,\n",
       "         9,  0, 24, 13,  9, 25,  9,  8, 30, 21,  0, 22, 12,  9, 30, 19, 19, 15,\n",
       "        13,  7, 31, 34, 17,  0, 18, 10,  0, 15, 32,  9,  5, 20, 30, 15, 11,  9,\n",
       "         6, 20,  5,  0, 22, 18,  0, 10, 23, 17,  7, 22, 34, 17,  0, 21, 19,  5,\n",
       "         7,  9, 21,  4, 35, 35, 32,  0, 17, 23, 16,  9, 20, 13,  7,  5, 15, 30,\n",
       "        17,  5, 15, 27, 21, 13, 21, 30, 17,  8,  0, 15, 32,  9,  5, 20, 30, 15,\n",
       "        11,  9,  6, 20,  5,  3,  0, 15, 18, 25,  9, 20, 29, 23, 19, 19,  9, 20,\n",
       "         0,  1, 15, 23,  2,  0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,\n",
       "         0, 18, 20,  0, 10,  5,  7, 22, 18, 20, 13, 28, 31, 34, 17,  0, 10,  5,\n",
       "         7, 22, 18, 20, 21, 30, 33, 31, 20, 13, 26, 30, 21,  0, 22, 12,  9,  0,\n",
       "        19, 20, 18,  8, 23,  7, 22,  0, 18, 10, 30,  0, 15, 18, 25,  9, 20,  0,\n",
       "        22, 20, 13,  5, 17, 11, 23, 15,  5, 20, 33, 31, 20, 13, 26, 30, 17,  8,\n",
       "        30, 17,  0, 23, 19, 19,  9, 20,  0, 22, 20, 13,  5, 17, 11, 23, 15,  5,\n",
       "        20, 33, 31, 20, 13, 26,  0,  1, 21,  9,  9, 33, 31, 20, 13, 26, 33, 23,\n",
       "        15, 22, 13, 19, 15, 13,  7, 31, 34, 17, 30, 17,  8, 33, 31, 20, 13, 26,\n",
       "         0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,  2,  4, 35])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eot = tok.eot_id\n",
    "tokens = []\n",
    "for example in [raw_example_1, raw_example_2]:\n",
    "    tokens.extend([eot])\n",
    "    tokens.extend(tok.encode(example.lower()))\n",
    "all_tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f45597-e81b-4dfb-a34a-fb210883041d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51779778-ccaf-4baf-b009-03c11fec951e",
   "metadata": {},
   "source": [
    "A machine learning model forward pass now uses the tokenization information, runs several layers of linear algebra on it, and then \"predicts\" the next token. When it is noisy (like you will see in this example), this process results in gibberish.  The training process changes the noise to pattern during the \"backward pass\" as you'll see.    We'll show 3 steps that are focused on training:\n",
    "1. **Data Loading** `x, y = train_loader.next_batch()` - this step pulls from the raw data enough tokens to complete a forward and backward pass.  If the model is inference only, this step is replaced with taking in the inference input and preparing it similarly as the forward pass.\n",
    "2. **Forward Pass** `logits, loss = model(x, y)` - using the data and the model architecture to predict the next token. When training we also compare against the expected to get loss, but in infrerence, we use the logits to complete the inference task.\n",
    "3. **Back Propagation, aka Backward Pass & Training** `loss.backward(); optimizer.step()` - using differentials to understand what parameters most impact the forward pass' impact on its prediction, comparing that against what is actually right based on the data loading step, and then making very minor adjustments to the impactful parameters with the hope it improves future predictions.\n",
    "\n",
    "The we'll show a final **Forward Pass** with the updated weights we did in #3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aefcbe-b05e-4e9a-a82f-46089bad50a5",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8293b18-5bdf-4693-82b3-466c20d679e9",
   "metadata": {},
   "source": [
    "To start, we need to get enough data to run the forward and backward passes.  Since our total dataset is likely too big to hold all at once in real practice, we would read just enough file information into memory so that we can run the passes, leaving memory and compute to be used on the passes instead of static data holding. \n",
    "To start, we have to identify the batch size and the model context length to determine how much data we need.  Consequently, these dimensions also form 2 of the 3 dimensions in the initial matrix.\n",
    "- **Batch Size (B)** - This is the number of examples you'll train on in a single pass. \n",
    "- **Context Length (T)** - This is the max number of tokens that a model can use in a single pass to generate the next token. If an example is below this length, it can be padded.\n",
    "  \n",
    "*Ideally both B and T are multiples of 2 to work nicely with chip architecture. This is a common theme across the board*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454fc40b-459c-457c-b5db-db0733549246",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_batch = 2 # Batch\n",
    "T_context = 8 # context length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62799c29-4030-4f06-af11-0192aa61b1e3",
   "metadata": {},
   "source": [
    "To start, we need to pull from our long raw_token list enough tokens for the forward pass. To be able to satisfy training `B` Batches `T` Context length, we need to pull out `B*T` tokens to slide the context window across the examples enough to satisfy the batch size.  Since the training will attempt to predict the last token given the previous tokens in context, we also need 1 more token at the end so that the last training example in the last batch can have the next token to validate against. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c595f6-0538-4a0b-b666-996fdc30f1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_position = 0\n",
    "tok_for_training = all_tokens[current_position:current_position + B_batch*T_context +1 ]\n",
    "tok_for_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6978a23-ad08-4ad3-870c-079b05a26b64",
   "metadata": {},
   "source": [
    "Now that we have our initial tokens to train on, we now need to convert it to a matrix that's ready for training. In this step we'll need to create our batches and setup two different arrays: 1/ the input, `x`, tokens that will result in 2/ the output `y` tokens. To create each example in the batch, every `T` tokens will be placed into its own row. \n",
    "\n",
    "Recall that training takes in a string of tokens the length of the context and then predicts the next token. Recall that when we extracted `tok_for_training` we added 1 extra token so that we can evaluate the prediction for the last example. Because of this, the input, `x`, will be all of the tokens up to the second to last element `[:-1]`.  \n",
    "\n",
    "It might be natural to think the output `y` would then just be the last token.But this is actually wasting valuable training loops.  Yes, there is the example that fills the context `T`, but we also have enough tokens in `tok_for_training` where any context length of `n` where `n<T` can also be used for inference since we have the `n+1` token available.  You can think of the following example:\n",
    "\n",
    "sentence: `Hi I am learning`. This sentence contains the following \"next tokens\" that can be learned:\n",
    "1. x: Hi I am  | y: learning\n",
    "2. x: Hi I     | y: am\n",
    "3. x: Hi       | y: I\n",
    "\n",
    "Because we have this triangle to create, our `y` can be much larger.  We can start with the second token and, go all the way to the last element we added for the last example `[1:'`.   \n",
    "\n",
    "\n",
    "We will now put this together and do the following:\n",
    "1. Extract the input `x` and then split it into an example for each batch `B`\n",
    "2. Extract the output `y` and then split it into an example for each batch `B`\n",
    "\n",
    "*Note: View can take `-1` which allows the matrix to infer the dimension so we do not need to pass in `T`, but given how many matrices we'll work with we want to make sure we're controlling the dimensions or erroring out if they do not match our expectations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8632328a-d0c0-4036-abea-601786682dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35, 15, 32,  9,  5, 20, 30, 15],\n",
       "        [11,  9,  6, 20,  5,  0, 13, 21]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tok_for_training[:-1].view(B_batch, T_context)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3440807c-eec6-4dfe-b671-31aaea855172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 32,  9,  5, 20, 30, 15, 11],\n",
       "        [ 9,  6, 20,  5,  0, 13, 21,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tok_for_training[1:].view(B_batch, T_context)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ab64c-4cae-4095-89b1-4534085323be",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b16235f-5aec-4268-baae-f36a2a377b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2620, -0.1038, -0.3010, -0.1772, -1.4823,  0.0314,  1.6311,  1.1587],\n",
       "        [ 2.6226, -0.3964,  0.0757, -1.9374,  0.3603, -1.2375, -0.2059,  0.5645]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_emb = nn.Embedding(36, 3)\n",
    "a = torch.randn(2, 8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aca904ca-509b-4ac9-a886-aabec833355f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 3]), torch.Size([2, 3, 8]), torch.Size([2, 3, 1, 8]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_emb(x).size(), tok_emb(x).permute(0,2,1).size(), tok_emb(x).permute(0,2,1).unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50f3c5c2-73ed-449f-b61d-0caf5e3eeb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1898, -1.1157,  0.2788],\n",
       "         [-1.0628, -0.1610,  0.2148],\n",
       "         [ 0.8359, -0.0341,  0.2810],\n",
       "         [-0.9667, -1.1414, -1.3115],\n",
       "         [-0.9154, -0.5388,  1.3685],\n",
       "         [-1.5558, -0.9423, -0.4886],\n",
       "         [ 0.7266,  1.0011,  1.0177],\n",
       "         [-1.0628, -0.1610,  0.2148]],\n",
       "\n",
       "        [[-1.4964, -1.4511,  1.2674],\n",
       "         [-0.9667, -1.1414, -1.3115],\n",
       "         [ 0.3240,  0.1004,  0.0178],\n",
       "         [-1.5558, -0.9423, -0.4886],\n",
       "         [-0.9154, -0.5388,  1.3685],\n",
       "         [-1.1520,  0.3227, -1.5533],\n",
       "         [-2.5592,  0.6948,  1.1710],\n",
       "         [ 2.4420, -1.5115, -0.2068]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb272139-80b0-41a6-a103-0ee917715085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1898, -1.0628,  0.8359, -0.9667, -0.9154, -1.5558,  0.7266,\n",
       "           -1.0628]],\n",
       "\n",
       "         [[-1.1157, -0.1610, -0.0341, -1.1414, -0.5388, -0.9423,  1.0011,\n",
       "           -0.1610]],\n",
       "\n",
       "         [[ 0.2788,  0.2148,  0.2810, -1.3115,  1.3685, -0.4886,  1.0177,\n",
       "            0.2148]]],\n",
       "\n",
       "\n",
       "        [[[-1.4964, -0.9667,  0.3240, -1.5558, -0.9154, -1.1520, -2.5592,\n",
       "            2.4420]],\n",
       "\n",
       "         [[-1.4511, -1.1414,  0.1004, -0.9423, -0.5388,  0.3227,  0.6948,\n",
       "           -1.5115]],\n",
       "\n",
       "         [[ 1.2674, -1.3115,  0.0178, -0.4886,  1.3685, -1.5533,  1.1710,\n",
       "           -0.2068]]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_emb(x).permute(0,2,1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b92ca36-0df2-45ab-8fa6-7e0b312b6010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be314109-2664-469d-9163-55110664053a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
