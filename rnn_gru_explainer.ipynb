{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ea846f-d5a9-4f61-b3b1-fed90e2edde3",
   "metadata": {},
   "source": [
    "# RNN GRU Explainer\n",
    "\n",
    "The goal is to walk through RNNs (recurring neural networks), there are 2 flavors: GRUs and LSTMs. We'll focus on Gated Recurrent Unit (GRUs).\n",
    "\n",
    "To help display the transformation, we'll use the first sentence from the [linear algebra wiki page](https://en.wikipedia.org/wiki/Linear_algebra) and [lu decomposition wiki page](https://en.wikipedia.org/wiki/LU_decomposition) as the topic is fitting and it shows us some non-standard patterns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f8d05-f237-4a81-8f88-be839e4a9e51",
   "metadata": {},
   "source": [
    "## Text Prep/Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1237d-fd4f-43bc-ba02-88e82368b385",
   "metadata": {},
   "source": [
    "we'll start with common preprocessing step of tokenizing the data.  This converts the string text into an array of numbers that can be used during the training loop.  I've built a very subtle byte-pair encdoing that has each unique character that appears and the top 5 merges. This keeps our vocab size small and managable for this example. Typically the vocab size is in the 100K+ range. A great library for this is `tiktoken`. Tokenization simply finds the longest pattern of characters that's in common with what was trained and replaces it with an integer that represents it.  This way we turn the text into a numeric array to simplify computing. import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baeedf57-4218-4b0e-be46-217723a9034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2240c1-dd4e-4f8a-9fb1-acff3ff200c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBPETokenizer:\n",
    "    def __init__(self, num_merges=5, eot_token='<|endoftext|>'):\n",
    "        self.num_merges = num_merges\n",
    "        self.eot_token = eot_token\n",
    "        self.eot_id = None\n",
    "        self.merges = []\n",
    "        self.pair_ranks = {}\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "\n",
    "    def _add_token(self, tok):\n",
    "        if tok in self.vocab:\n",
    "            return self.vocab[tok]\n",
    "        i = len(self.vocab)\n",
    "        self.vocab[tok] = i\n",
    "        self.id_to_token[i] = tok\n",
    "        return i\n",
    "\n",
    "    def _get_bigrams(self, seq):\n",
    "        for i in range(len(seq) - 1):\n",
    "            yield (seq[i], seq[i + 1])\n",
    "\n",
    "    def _merge_once(self, seq, pair):\n",
    "        a, b = pair\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            if i < len(seq) - 1 and seq[i] == a and seq[i + 1] == b:\n",
    "                out.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                out.append(seq[i])\n",
    "                i += 1\n",
    "        return out\n",
    "\n",
    "    def train(self, corpus):\n",
    "        # corpus: list[str]\n",
    "        text = ''.join(corpus).lower()\n",
    "        seq = list(text)\n",
    "        merges = []\n",
    "        for _ in range(self.num_merges):\n",
    "            counts = Counter(self._get_bigrams(seq))\n",
    "            if not counts: break\n",
    "            best_pair, _ = counts.most_common(1)[0]\n",
    "            merges.append(best_pair)\n",
    "            seq = self._merge_once(seq, best_pair)\n",
    "        self.merges = merges\n",
    "        self.pair_ranks = {p: i for i, p in enumerate(self.merges)}\n",
    "\n",
    "        self.vocab = {}\n",
    "        self.id_to_token = {}\n",
    "        for ch in sorted(set(text)):\n",
    "            self._add_token(ch)\n",
    "        for a, b in self.merges:\n",
    "            self._add_token(a + b)\n",
    "        self.eot_id = self._add_token(self.eot_token)\n",
    "\n",
    "    def encode(self, text, force_last_eot=True):\n",
    "        # treat literal eot marker as special; remove it from content\n",
    "        if self.eot_token in text:\n",
    "            text = text.replace(self.eot_token, '')\n",
    "        seq = list(text)\n",
    "\n",
    "        # make sure all seen base chars exist\n",
    "        for ch in set(seq):\n",
    "            if ch not in self.vocab:\n",
    "                self._add_token(ch)\n",
    "\n",
    "        # greedy BPE using learned pair ranks\n",
    "        if self.merges:\n",
    "            while True:\n",
    "                best_pair, best_rank = None, None\n",
    "                for p in self._get_bigrams(seq):\n",
    "                    r = self.pair_ranks.get(p)\n",
    "                    if r is not None and (best_rank is None or r < best_rank):\n",
    "                        best_pair, best_rank = p, r\n",
    "                if best_pair is None:\n",
    "                    break\n",
    "                seq = self._merge_once(seq, best_pair)\n",
    "\n",
    "        # ensure all tokens in seq exist in vocab (e.g., if new chars appeared)\n",
    "        for tok in seq:\n",
    "            if tok not in self.vocab:\n",
    "                self._add_token(tok)\n",
    "\n",
    "        ids = [self.vocab[tok] for tok in seq]\n",
    "\n",
    "        # FORCE: append EOT id if not already last\n",
    "        if force_last_eot:\n",
    "            if not ids or ids[-1] != self.eot_id:\n",
    "                ids.append(self.eot_id)\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # drop trailing EOT if present\n",
    "        if ids and self.eot_id is not None and ids[-1] == self.eot_id:\n",
    "            ids = ids[:-1]\n",
    "        toks = [self.id_to_token[i] for i in ids]\n",
    "        return ''.join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35d09cf-0ce1-47a0-a93f-8213bea8f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_example_1 = r'''Linear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis, a branch of mathematical analysis, may be viewed as the application of linear algebra to function spaces.'''\n",
    "raw_example_2 = r'''In numerical analysis and linear algebra, lower–upper (LU) decomposition or factorization factors a matrix as the product of a lower triangular matrix and an upper triangular matrix (see matrix multiplication and matrix decomposition).'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7064c634-a608-4a62-93fe-c89219aa5dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 'a'), ('a', 't'), ('i', 'n'), (' ', 'm'), ('i', 'o')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = SimpleBPETokenizer(num_merges=5)\n",
    "tok.train([raw_example_1,raw_example_2])\n",
    "tok.merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133f8d70-16cd-4327-91a2-4e887612bcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '(': 1,\n",
       " ')': 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " 'a': 5,\n",
       " 'b': 6,\n",
       " 'c': 7,\n",
       " 'd': 8,\n",
       " 'e': 9,\n",
       " 'f': 10,\n",
       " 'g': 11,\n",
       " 'h': 12,\n",
       " 'i': 13,\n",
       " 'j': 14,\n",
       " 'l': 15,\n",
       " 'm': 16,\n",
       " 'n': 17,\n",
       " 'o': 18,\n",
       " 'p': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " '–': 29,\n",
       " ' a': 30,\n",
       " 'at': 31,\n",
       " 'in': 32,\n",
       " ' m': 33,\n",
       " 'io': 34,\n",
       " '<|endoftext|>': 35}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9804d527-b590-4bb5-8158-8cdcbc179719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tok.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29443925-8749-4b7c-a500-4a3bdbf808d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0,  7,\n",
       "         9, 17, 22, 20,  5, 15,  0, 22, 18, 30, 15, 16, 18, 21, 22, 30, 15, 15,\n",
       "        30, 20,  9,  5, 21,  0, 18, 10, 33, 31, 12,  9, 16, 31, 13,  7, 21,  4,\n",
       "         0, 10, 18, 20,  0, 32, 21, 22,  5, 17,  7,  9,  3,  0, 15, 32,  9,  5,\n",
       "        20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0, 10, 23, 17,  8,  5, 16,\n",
       "         9, 17, 22,  5, 15,  0, 32, 33, 18,  8,  9, 20, 17,  0, 19, 20,  9, 21,\n",
       "         9, 17, 22, 31, 34, 17, 21,  0, 18, 10,  0, 11,  9, 18, 16,  9, 22, 20,\n",
       "        27,  3,  0, 32,  7, 15, 23,  8, 32, 11,  0, 10, 18, 20,  0,  8,  9, 10,\n",
       "        32, 32, 11,  0,  6,  5, 21, 13,  7,  0, 18,  6, 14,  9,  7, 22, 21,  0,\n",
       "        21, 23,  7, 12, 30, 21,  0, 15, 32,  9, 21,  3,  0, 19, 15,  5, 17,  9,\n",
       "        21, 30, 17,  8,  0, 20, 18, 22, 31, 34, 17, 21,  4, 30, 15, 21, 18,  3,\n",
       "         0, 10, 23, 17,  7, 22, 34, 17,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,\n",
       "         3, 30,  0,  6, 20,  5, 17,  7, 12,  0, 18, 10, 33, 31, 12,  9, 16, 31,\n",
       "        13,  7,  5, 15, 30, 17,  5, 15, 27, 21, 13, 21,  3, 33,  5, 27,  0,  6,\n",
       "         9,  0, 24, 13,  9, 25,  9,  8, 30, 21,  0, 22, 12,  9, 30, 19, 19, 15,\n",
       "        13,  7, 31, 34, 17,  0, 18, 10,  0, 15, 32,  9,  5, 20, 30, 15, 11,  9,\n",
       "         6, 20,  5,  0, 22, 18,  0, 10, 23, 17,  7, 22, 34, 17,  0, 21, 19,  5,\n",
       "         7,  9, 21,  4, 35, 35, 32,  0, 17, 23, 16,  9, 20, 13,  7,  5, 15, 30,\n",
       "        17,  5, 15, 27, 21, 13, 21, 30, 17,  8,  0, 15, 32,  9,  5, 20, 30, 15,\n",
       "        11,  9,  6, 20,  5,  3,  0, 15, 18, 25,  9, 20, 29, 23, 19, 19,  9, 20,\n",
       "         0,  1, 15, 23,  2,  0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,\n",
       "         0, 18, 20,  0, 10,  5,  7, 22, 18, 20, 13, 28, 31, 34, 17,  0, 10,  5,\n",
       "         7, 22, 18, 20, 21, 30, 33, 31, 20, 13, 26, 30, 21,  0, 22, 12,  9,  0,\n",
       "        19, 20, 18,  8, 23,  7, 22,  0, 18, 10, 30,  0, 15, 18, 25,  9, 20,  0,\n",
       "        22, 20, 13,  5, 17, 11, 23, 15,  5, 20, 33, 31, 20, 13, 26, 30, 17,  8,\n",
       "        30, 17,  0, 23, 19, 19,  9, 20,  0, 22, 20, 13,  5, 17, 11, 23, 15,  5,\n",
       "        20, 33, 31, 20, 13, 26,  0,  1, 21,  9,  9, 33, 31, 20, 13, 26, 33, 23,\n",
       "        15, 22, 13, 19, 15, 13,  7, 31, 34, 17, 30, 17,  8, 33, 31, 20, 13, 26,\n",
       "         0,  8,  9,  7, 18, 16, 19, 18, 21, 13, 22, 34, 17,  2,  4, 35])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eot = tok.eot_id\n",
    "tokens = []\n",
    "for example in [raw_example_1, raw_example_2]:\n",
    "    tokens.extend([eot])\n",
    "    tokens.extend(tok.encode(example.lower()))\n",
    "all_tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f0cb1-fdac-400c-a80d-1a5da154434c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd76b6-dfd5-4f08-a289-630af13649f0",
   "metadata": {},
   "source": [
    "A machine learning model forward pass now uses the tokenization information, runs several layers of linear algebra on it, and then \"predicts\" the next token. When it is noisy (like you will see in this example), this process results in gibberish.  The training process changes the noise to pattern during the \"backward pass\" as you'll see.    We'll show 3 steps that are focused on training:\n",
    "1. **Data Loading** `x, y = train_loader.next_batch()` - this step pulls from the raw data enough tokens to complete a forward and backward pass.  If the model is inference only, this step is replaced with taking in the inference input and preparing it similarly as the forward pass.\n",
    "2. **Forward Pass** `logits, loss = model(x, y)` - using the data and the model architecture to predict the next token. When training we also compare against the expected to get loss, but in infrerence, we use the logits to complete the inference task.\n",
    "3. **Backward Pass & Training** `loss.backward(); optimizer.step()` - using differentials to understand what parameters most impact the forward pass' impact on its prediction, comparing that against what is actually right based on the data loading step, and then making very minor adjustments to the impactful parameters with the hope it improves future predictions.\n",
    "\n",
    "The we'll show a final **Forward Pass** with the updated weights we did in #3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8d4c4-ae00-465d-ae6f-ea6e1be858f0",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d7e34-19d0-4c9b-bc7c-b89c09052167",
   "metadata": {},
   "source": [
    "To start, we need to get enough data to run the forward and backward passes.  Since our total dataset is likely too big to hold all at once in real practice, we would read just enough file information into memory so that we can run the passes, leaving memory and compute to be used on the passes instead of static data holding. \n",
    "To start, we have to identify the batch size and the model context length to determine how much data we need.  Consequently, these dimensions also form 2 of the 3 dimensions in the initial matrix.\n",
    "- **Batch Size (B)** - This is the number of examples you'll train on in a single pass. \n",
    "- **Context Length (T)** - This is the max number of tokens that a model can use in a single pass to generat the next token. If an example is below this length, it can be padded.\n",
    "  \n",
    "*Ideally both B and T are multiples of 2 to work nicely with chip architecture. This is a common theme across the board*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1349878b-f4cd-4691-93fc-f8f2d76cb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2 # Batch\n",
    "T = 8 # context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eda05fa-9c31-4618-ae8c-ed1317467795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_position = 0\n",
    "tok_for_training = all_tokens[current_position:current_position + B*T +1 ]\n",
    "tok_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cc8223-0f42-4756-af7c-3af62ce59551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35, 15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36ec177-74d7-4cb9-b84d-75a10a6c6694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35, 15, 32,  9,  5, 20, 30, 15],\n",
       "        [11,  9,  6, 20,  5,  0, 13, 21]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tok_for_training[:-1].view(B, T)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d87eb2-5bc8-44cb-80d4-806c3a3bf93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 32,  9,  5, 20, 30, 15, 11],\n",
       "        [ 9,  6, 20,  5,  0, 13, 21,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=tok_for_training[1:].view(B, T)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd96f05-28c7-482a-bd47-d8226e65d235",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e785e1-7328-4b6f-83f9-a98247f06bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa762304-604b-458a-b0d5-2d787de76448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_batch, T_context = x.size()\n",
    "B_batch, T_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6d9984-9890-4b37-b538-5a09fdb7efed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 4 # level of embedding of input tokens\n",
    "n_embd, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3ccab-d62d-41f8-9539-4a257e9ca2a8",
   "metadata": {},
   "source": [
    "**Embedding input**\n",
    "\n",
    "Same as with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be607d75-1447-4339-9145-0f18f7e294b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wte = nn.Embedding(vocab_size, n_embd)\n",
    "torch.nn.init.ones_(wte.weight)\n",
    "wte.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b37914-4be6-4ed6-ad7b-daa43db954ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4]),\n",
       " tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wte(x)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf83182-f32a-4da0-93c8-8bb4f41cce49",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa012d0-91b1-474d-b961-ebfb4ef1889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.1, inplace=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.1)\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b56d86-9cfe-4b21-ba08-1b1dba07fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1111, 1.1111, 1.1111, 0.0000],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [0.0000, 0.0000, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 0.0000, 1.1111, 1.1111]],\n",
       "\n",
       "        [[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 0.0000, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 0.0000, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 0.0000]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbacb6-0960-4e47-b541-342263b58c57",
   "metadata": {},
   "source": [
    "**Recurrent Block**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c2ecb-580d-402c-b932-f00d799ab5b1",
   "metadata": {},
   "source": [
    "z is the update gate, r the reset gate, and h~t is the candidate hidden\n",
    "\n",
    "Short version:\n",
    "\n",
    "* `x2g` = “input-to-gates” affine: maps the current input $(x_t\\in\\mathbb{R}^{B\\times E})$ to a concatenated vector of length (3H). Splitting it gives $(z_x, r_x, n_x \\in \\mathbb{R}^{B\\times H})$.\n",
    "* `h2g` = “hidden-to-gates” affine: maps the previous hidden $(h_{t-1}\\in\\mathbb{R}^{B\\times H})$ to another (3H) vector. Splitting it gives $(z_h, r_h, n_h \\in \\mathbb{R}^{B\\times H})$.\n",
    "* `zx`, `rx`, `nx` are the pre-activation contributions from the input to the GRU’s update, reset, and “new state” (candidate) parts, respectively.\n",
    "* `zh`, `rh`, `nh` are the corresponding contributions from the previous hidden state.\n",
    "\n",
    "Putting it together (your code’s math):\n",
    "\n",
    "$\\begin{aligned}\n",
    "z_x, r_x, n_x &= \\mathrm{x2g}(x_t)\\ \\text{chunked into 3 parts},\n",
    "z_h, r_h, n_h &= \\mathrm{h2g}(h_{t-1})\\ \\text{chunked into 3 parts},\n",
    "z &= \\sigma(z_x + z_h),\n",
    "r &= \\sigma(r_x + r_h),\n",
    "\\tilde{h}_t &= \\tanh!\\big(n_x + r \\odot n_h\\big),\n",
    "h_t &= (1 - z)\\odot \\tilde{h}*t + z\\odot h*{t-1}.\n",
    "\\end{aligned}$\n",
    "\n",
    "Notes: (z) is the update gate, (r) the reset gate, and $(\\tilde{h}_t)$ is the candidate hidden. Each “chunk” has shape ((B,H)). Also, there’s no `z2g` in that snippet—you probably meant `x2g`; the “2g” just reads “to-gates.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21e8264-8bef-4002-af8e-fb022891468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb643927-6944-4785-ac3a-935d1f08b17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 4]),\n",
       " Parameter containing:\n",
       " tensor([[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000]], requires_grad=True),\n",
       " torch.Size([15]),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2g = nn.Linear(n_embd, 3 * hidden_size, bias=True)\n",
    "torch.nn.init.constant_(x2g.weight, 0.500)\n",
    "torch.nn.init.zeros_(x2g.bias)\n",
    "x2g.weight.size(), x2g.weight, x2g.bias.size(), x2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cd4aed3-b539-488f-a4ea-0f081ebc100b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 5]),\n",
       " Parameter containing:\n",
       " tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500]], requires_grad=True),\n",
       " torch.Size([15]),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2g = nn.Linear(hidden_size, 3 * hidden_size, bias=True)\n",
    "torch.nn.init.constant_(h2g.weight, 0.250)\n",
    "torch.nn.init.zeros_(h2g.bias)\n",
    "h2g.weight.size(), h2g.weight, h2g.bias.size(), h2g.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea925e-09b9-423c-994c-28bb2061765d",
   "metadata": {},
   "source": [
    "since first pass, incoming weight (h_t) are seroed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09c99f-ab91-4dcb-8f0b-295c3f2a30a2",
   "metadata": {},
   "source": [
    "first pass (future will loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f7b252-dae3-4243-8b6c-ec16a292c1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1111, 1.1111, 1.1111, 0.0000],\n",
       "        [1.1111, 1.1111, 1.1111, 1.1111]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = x[:, 0, :]\n",
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58799445-c5d7-49a8-9314-58feefba9e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 15]),\n",
       " 'zx',\n",
       " tensor([[1.6667, 1.6667, 1.6667, 1.6667, 1.6667],\n",
       "         [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]),\n",
       " 'rx',\n",
       " tensor([[1.6667, 1.6667, 1.6667, 1.6667, 1.6667],\n",
       "         [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]),\n",
       " 'nx',\n",
       " tensor([[1.6667, 1.6667, 1.6667, 1.6667, 1.6667],\n",
       "         [2.2222, 2.2222, 2.2222, 2.2222, 2.2222]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x2g(x_0)\n",
    "zx, rx, nx = x_t.chunk(3, dim=-1)\n",
    "\n",
    "x_t.size(), 'zx', zx, zx.size(), 'rx',rx, rx.size(),'nx',nx, nx.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423157a4-0baf-41fb-abc2-bb64289d9499",
   "metadata": {},
   "source": [
    "Now we have to do the incoming weights, since this is round 0, they'll be 0 since nothing preceeds the first token. we'll set `h_t` to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a3613db-8171-4b5d-927c-e213399d2fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_init = torch.zeros(B_batch, hidden_size) \n",
    "h_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99d66f20-4f07-4ca8-b586-e9d82bca89db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 15]),\n",
       " 'zh',\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]),\n",
       " 'rh',\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]),\n",
       " 'nh',\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], grad_fn=<SplitBackward0>),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t = h2g(h_init)\n",
    "zh, rh, nh = h_t.chunk(3, dim=-1)\n",
    "\n",
    "h_t.size(), 'zh', zh, zh.size(), 'rh',rh, rh.size(),'nh',nh, nh.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a718b-063b-4f8a-8dfe-bc8040e2badc",
   "metadata": {},
   "source": [
    "combine the pieces of of the inputs and the previous:\n",
    "\n",
    "https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7128c628-08d2-4c5c-88df-4422253833b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.8411, 0.8411, 0.8411, 0.8411, 0.8411],\n",
       "         [0.9022, 0.9022, 0.9022, 0.9022, 0.9022]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.sigmoid(zx + zh)\n",
    "z.size(), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "564d821f-cdd1-4b3c-a547-c98aaa97e599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.8411, 0.8411, 0.8411, 0.8411, 0.8411],\n",
       "         [0.9022, 0.9022, 0.9022, 0.9022, 0.9022]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.sigmoid(rx + rh)\n",
    "r.size(), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d85edd8d-b052-4e65-bef7-2aefb8dd6ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.9311, 0.9311, 0.9311, 0.9311, 0.9311],\n",
       "         [0.9768, 0.9768, 0.9768, 0.9768, 0.9768]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.tanh(nx + r * nh)\n",
    "\n",
    "n.size(), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2247d741-2729-40ab-b81a-72542145bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0.1479, 0.1479, 0.1479, 0.1479, 0.1479],\n",
       "         [0.0955, 0.0955, 0.0955, 0.0955, 0.0955]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t = (1 - z) * n + z * h_init\n",
    "h_t.size(), h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088318f-4aa6-47cc-a3c5-3e633b517129",
   "metadata": {},
   "source": [
    "## now do it recursively for the rest of the batch size\n",
    "\n",
    "first we'll need to keep track of h_t for each loop for training, so let's start collecting them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5712a754-aaaf-411f-8465-8c9c69569ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.1479, 0.1479, 0.1479, 0.1479, 0.1479]],\n",
       " \n",
       "         [[0.0955, 0.0955, 0.0955, 0.0955, 0.0955]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = []\n",
    "hs.append(h_t.unsqueeze(1))\n",
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4124348-ff19-4342-bb51-4df571ef4c30",
   "metadata": {},
   "source": [
    "start at 1 since we did the \"0\" pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c0be513-11d4-4856-94cd-665d63b3d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 1\n",
      "tensor([[0.2170, 0.2170, 0.2170, 0.2170, 0.2170],\n",
      "        [0.2172, 0.2172, 0.2172, 0.2172, 0.2172]], grad_fn=<AddBackward0>)\n",
      "t: 2\n",
      "tensor([[0.3477, 0.3477, 0.3477, 0.3477, 0.3477],\n",
      "        [0.2759, 0.2759, 0.2759, 0.2759, 0.2759]], grad_fn=<AddBackward0>)\n",
      "t: 3\n",
      "tensor([[0.3898, 0.3898, 0.3898, 0.3898, 0.3898],\n",
      "        [0.3266, 0.3266, 0.3266, 0.3266, 0.3266]], grad_fn=<AddBackward0>)\n",
      "t: 4\n",
      "tensor([[0.4273, 0.4273, 0.4273, 0.4273, 0.4273],\n",
      "        [0.3711, 0.3711, 0.3711, 0.3711, 0.3711]], grad_fn=<AddBackward0>)\n",
      "t: 5\n",
      "tensor([[0.4610, 0.4610, 0.4610, 0.4610, 0.4610],\n",
      "        [0.4346, 0.4346, 0.4346, 0.4346, 0.4346]], grad_fn=<AddBackward0>)\n",
      "t: 6\n",
      "tensor([[0.4915, 0.4915, 0.4915, 0.4915, 0.4915],\n",
      "        [0.4676, 0.4676, 0.4676, 0.4676, 0.4676]], grad_fn=<AddBackward0>)\n",
      "t: 7\n",
      "tensor([[0.5365, 0.5365, 0.5365, 0.5365, 0.5365],\n",
      "        [0.5160, 0.5160, 0.5160, 0.5160, 0.5160]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(1,T):\n",
    "    x_t = x[:, t, :]\n",
    "    h_prev = h_t\n",
    "    zx, rx, nx = x2g(x_t).chunk(3, dim=-1)\n",
    "    zh, rh, nh = h2g(h_prev).chunk(3, dim=-1)\n",
    "    z = torch.sigmoid(zx + zh)\n",
    "    r = torch.sigmoid(rx + rh)\n",
    "    n = torch.tanh(nx + r * nh)\n",
    "    h_t = (1 - z) * n + z * h_prev\n",
    "    \n",
    "    print(f't: {t}')\n",
    "    print(h_t)\n",
    "    hs.append(h_t.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de5f7269-332d-48e5-ba64-d36de54ac446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.1479, 0.1479, 0.1479, 0.1479, 0.1479]],\n",
       " \n",
       "         [[0.0955, 0.0955, 0.0955, 0.0955, 0.0955]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.2170, 0.2170, 0.2170, 0.2170, 0.2170]],\n",
       " \n",
       "         [[0.2172, 0.2172, 0.2172, 0.2172, 0.2172]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.3477, 0.3477, 0.3477, 0.3477, 0.3477]],\n",
       " \n",
       "         [[0.2759, 0.2759, 0.2759, 0.2759, 0.2759]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.3898, 0.3898, 0.3898, 0.3898, 0.3898]],\n",
       " \n",
       "         [[0.3266, 0.3266, 0.3266, 0.3266, 0.3266]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4273, 0.4273, 0.4273, 0.4273, 0.4273]],\n",
       " \n",
       "         [[0.3711, 0.3711, 0.3711, 0.3711, 0.3711]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4610, 0.4610, 0.4610, 0.4610, 0.4610]],\n",
       " \n",
       "         [[0.4346, 0.4346, 0.4346, 0.4346, 0.4346]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4915, 0.4915, 0.4915, 0.4915, 0.4915]],\n",
       " \n",
       "         [[0.4676, 0.4676, 0.4676, 0.4676, 0.4676]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.5365, 0.5365, 0.5365, 0.5365, 0.5365]],\n",
       " \n",
       "         [[0.5160, 0.5160, 0.5160, 0.5160, 0.5160]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583b860-2977-49cb-8945-9c60eeb3d479",
   "metadata": {},
   "source": [
    "Combine out recurring inputs into the 2 different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5214c260-55b7-4c85-a1b2-97aa5fb09603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1479, 0.1479, 0.1479, 0.1479, 0.1479],\n",
       "         [0.2170, 0.2170, 0.2170, 0.2170, 0.2170],\n",
       "         [0.3477, 0.3477, 0.3477, 0.3477, 0.3477],\n",
       "         [0.3898, 0.3898, 0.3898, 0.3898, 0.3898],\n",
       "         [0.4273, 0.4273, 0.4273, 0.4273, 0.4273],\n",
       "         [0.4610, 0.4610, 0.4610, 0.4610, 0.4610],\n",
       "         [0.4915, 0.4915, 0.4915, 0.4915, 0.4915],\n",
       "         [0.5365, 0.5365, 0.5365, 0.5365, 0.5365]],\n",
       "\n",
       "        [[0.0955, 0.0955, 0.0955, 0.0955, 0.0955],\n",
       "         [0.2172, 0.2172, 0.2172, 0.2172, 0.2172],\n",
       "         [0.2759, 0.2759, 0.2759, 0.2759, 0.2759],\n",
       "         [0.3266, 0.3266, 0.3266, 0.3266, 0.3266],\n",
       "         [0.3711, 0.3711, 0.3711, 0.3711, 0.3711],\n",
       "         [0.4346, 0.4346, 0.4346, 0.4346, 0.4346],\n",
       "         [0.4676, 0.4676, 0.4676, 0.4676, 0.4676],\n",
       "         [0.5160, 0.5160, 0.5160, 0.5160, 0.5160]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat(hs, dim=1) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c77db-2d10-454f-b512-92ac5b024e61",
   "metadata": {},
   "source": [
    "**Dropout** to fight vanishing / exploding gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14428ec8-69e9-4605-a6fa-eb1012337be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 5]),\n",
       " tensor([[[0.1644, 0.1644, 0.1644, 0.1644, 0.1644],\n",
       "          [0.2411, 0.2411, 0.2411, 0.2411, 0.2411],\n",
       "          [0.3864, 0.3864, 0.3864, 0.3864, 0.3864],\n",
       "          [0.4331, 0.4331, 0.4331, 0.4331, 0.4331],\n",
       "          [0.4748, 0.0000, 0.4748, 0.4748, 0.4748],\n",
       "          [0.5122, 0.5122, 0.5122, 0.0000, 0.5122],\n",
       "          [0.5461, 0.5461, 0.5461, 0.5461, 0.5461],\n",
       "          [0.5961, 0.5961, 0.0000, 0.5961, 0.5961]],\n",
       " \n",
       "         [[0.1061, 0.1061, 0.1061, 0.1061, 0.1061],\n",
       "          [0.2414, 0.2414, 0.2414, 0.2414, 0.2414],\n",
       "          [0.0000, 0.3065, 0.3065, 0.3065, 0.3065],\n",
       "          [0.3629, 0.3629, 0.3629, 0.3629, 0.3629],\n",
       "          [0.4124, 0.4124, 0.4124, 0.4124, 0.4124],\n",
       "          [0.4829, 0.4829, 0.4829, 0.4829, 0.4829],\n",
       "          [0.5196, 0.0000, 0.5196, 0.5196, 0.5196],\n",
       "          [0.5733, 0.5733, 0.0000, 0.0000, 0.5733]]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22593c65-be72-436f-9e1c-8620c22c04ab",
   "metadata": {},
   "source": [
    "**Output Head**\n",
    "projects down from the hiden size to the vocab for us to get logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27e76d90-e130-4e4f-a221-18ee7461876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 5]),\n",
       " Parameter containing:\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]], requires_grad=True))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "torch.nn.init.ones_(lm_head.weight)\n",
    "lm_head.weight.size(), lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19b23a27-073d-499e-a5d3-5d1cc5d42f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 36]),\n",
       " tensor([[[0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "           0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "           0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "           0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "           0.8218, 0.8218, 0.8218, 0.8218],\n",
       "          [1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "           1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "           1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "           1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "           1.2053, 1.2053, 1.2053, 1.2053],\n",
       "          [1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "           1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "           1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "           1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "           1.9318, 1.9318, 1.9318, 1.9318],\n",
       "          [2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "           2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "           2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "           2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "           2.1657, 2.1657, 2.1657, 2.1657],\n",
       "          [1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "           1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "           1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "           1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "           1.8992, 1.8992, 1.8992, 1.8992],\n",
       "          [2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "           2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "           2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "           2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "           2.0489, 2.0489, 2.0489, 2.0489],\n",
       "          [2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "           2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "           2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "           2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "           2.7306, 2.7306, 2.7306, 2.7306],\n",
       "          [2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "           2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "           2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "           2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "           2.3844, 2.3844, 2.3844, 2.3844]],\n",
       " \n",
       "         [[0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "           0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "           0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "           0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "           0.5306, 0.5306, 0.5306, 0.5306],\n",
       "          [1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "           1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "           1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "           1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "           1.2069, 1.2069, 1.2069, 1.2069],\n",
       "          [1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "           1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "           1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "           1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "           1.2261, 1.2261, 1.2261, 1.2261],\n",
       "          [1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "           1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "           1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "           1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "           1.8146, 1.8146, 1.8146, 1.8146],\n",
       "          [2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "           2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "           2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "           2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "           2.0619, 2.0619, 2.0619, 2.0619],\n",
       "          [2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "           2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "           2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "           2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "           2.4147, 2.4147, 2.4147, 2.4147],\n",
       "          [2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "           2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "           2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "           2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "           2.0783, 2.0783, 2.0783, 2.0783],\n",
       "          [1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "           1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "           1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "           1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "           1.7200, 1.7200, 1.7200, 1.7200]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(x)\n",
    "\n",
    "logits.shape, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c01b9-d09b-4708-bd9e-3aceeeb9cb18",
   "metadata": {},
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8423d81b-3ceb-44a0-b8dd-7b7ffe5cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dce85cc-5c7e-47bf-8f0e-e23b7f6aa337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]),\n",
       " tensor([15, 32,  9,  5, 20, 30, 15, 11,  9,  6, 20,  5,  0, 13, 21,  0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_flat = y.view(-1)\n",
    "y_flat.shape, y_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03a2daf1-b8cb-4660-9b46-c60d6c95ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 36]),\n",
       " tensor([[0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "          0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "          0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218,\n",
       "          0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218, 0.8218],\n",
       "         [1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "          1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "          1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053,\n",
       "          1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053, 1.2053],\n",
       "         [1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "          1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "          1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318,\n",
       "          1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318, 1.9318],\n",
       "         [2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "          2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "          2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657,\n",
       "          2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657, 2.1657],\n",
       "         [1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "          1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "          1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992,\n",
       "          1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992, 1.8992],\n",
       "         [2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "          2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "          2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489,\n",
       "          2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489, 2.0489],\n",
       "         [2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "          2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "          2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306,\n",
       "          2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306, 2.7306],\n",
       "         [2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "          2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "          2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844,\n",
       "          2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844, 2.3844],\n",
       "         [0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "          0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "          0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306,\n",
       "          0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306, 0.5306],\n",
       "         [1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "          1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "          1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069,\n",
       "          1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069],\n",
       "         [1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "          1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "          1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261,\n",
       "          1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261, 1.2261],\n",
       "         [1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "          1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "          1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146,\n",
       "          1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146, 1.8146],\n",
       "         [2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "          2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "          2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619,\n",
       "          2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619, 2.0619],\n",
       "         [2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "          2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "          2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147,\n",
       "          2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147, 2.4147],\n",
       "         [2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "          2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "          2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783,\n",
       "          2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783, 2.0783],\n",
       "         [1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "          1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "          1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200,\n",
       "          1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200, 1.7200]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.view(-1, logits.size(-1))\n",
    "logits_flat.shape, logits_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b287d1b-c82f-4f51-bb49-7a542ddd3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), tensor(3.5835, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits_flat, y_flat)\n",
    "loss.shape, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587d633-a3ed-49e3-a90a-9c505b079665",
   "metadata": {},
   "source": [
    "## Back Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0455dc7a-fab4-4844-bf37-2ac311226907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head.zero_grad()\n",
    "h2g.zero_grad()\n",
    "x2g.zero_grad()\n",
    "wte.zero_grad()\n",
    "\n",
    "\n",
    "# validate gradients\n",
    "lm_head.weight.grad, wte.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0b7acd2-55bc-4fe6-9c41-1ddc0ee05eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "119fa3fb-0e8c-4db3-9df8-4a1b361279d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0511, -0.0523, -0.0168, -0.0166, -0.0506],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0392, -0.0404, -0.0407, -0.0406, -0.0387],\n",
       "         [-0.0046, -0.0058, -0.0061, -0.0059, -0.0040],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0203, -0.0215, -0.0218, -0.0216, -0.0197],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0267, -0.0279,  0.0090, -0.0281, -0.0262],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0197, -0.0209, -0.0212, -0.0210, -0.0191],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0339, -0.0351, -0.0354, -0.0352, -0.0334],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0192, -0.0098, -0.0398, -0.0397, -0.0378],\n",
       "         [-0.0220,  0.0093, -0.0235, -0.0233, -0.0214],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0215, -0.0227, -0.0230,  0.0092, -0.0210],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [-0.0046, -0.0058, -0.0061, -0.0059, -0.0040],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110],\n",
       "         [ 0.0105,  0.0093,  0.0090,  0.0092,  0.0110]]),\n",
       " tensor([[-3.9474e-09,  0.0000e+00, -3.9474e-09, -3.9474e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-8.3396e-09, -8.3396e-09, -8.3396e-09, -8.3396e-09],\n",
       "         [-8.6900e-09, -8.6900e-09, -8.6900e-09, -8.6900e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.1367e-08, -2.1367e-08, -5.1499e-09, -2.1367e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.4442e-08, -1.4442e-08, -1.4442e-08, -1.4442e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.6639e-09, -1.6639e-09, -1.6639e-09, -1.6639e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.0808e-08, -9.9713e-09, -1.0808e-08, -1.0808e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-9.9036e-09, -9.9036e-09, -9.9036e-09, -9.9036e-09],\n",
       "         [-1.4772e-09, -1.4772e-09, -1.4772e-09,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.3501e-09, -1.3501e-09, -1.3501e-09, -1.3501e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -8.5419e-09, -8.5419e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.7274e-08, -1.7274e-08, -1.7274e-08,  0.0000e+00]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head.weight.grad, wte.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8564d2f-34d0-4526-80b7-69337e2a7549",
   "metadata": {},
   "source": [
    "## Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2b11f32-0c10-480d-9690-402132913444",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Huge learning rate to emphasize\n",
    "learning_rate = 5.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5c59984-6d36-4e78-b7fc-cf4623294915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.2555, 1.2615, 1.0838, 1.0831, 1.2528],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.1962, 1.2022, 1.2037, 1.2030, 1.1936],\n",
       "        [1.0229, 1.0289, 1.0304, 1.0297, 1.0202],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.1014, 1.1073, 1.1088, 1.1081, 1.0987],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.1337, 1.1397, 0.9549, 1.1405, 1.1311],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.0984, 1.1043, 1.1059, 1.1051, 1.0957],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.1695, 1.1755, 1.1770, 1.1762, 1.1668],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.0958, 1.0492, 1.1991, 1.1984, 1.1890],\n",
       "        [1.1098, 0.9534, 1.1173, 1.1166, 1.1072],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.1075, 1.1135, 1.1150, 0.9542, 1.1049],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [1.0228, 1.0288, 1.0303, 1.0296, 1.0201],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448],\n",
       "        [0.9475, 0.9534, 0.9549, 0.9542, 0.9448]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lm_head.weight -= learning_rate * lm_head.weight.grad\n",
    "lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44461eb7-82b4-4383-afab-ef1c18203289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.2500, 0.2500, 0.2500, 0.2500, 0.2500]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.4692e-07,  2.2701e-07,  2.0391e-07,  1.9728e-07,  2.5823e-07,\n",
       "         -9.2556e-10, -8.0872e-10, -7.6041e-10, -7.1028e-10, -9.3874e-10,\n",
       "         -2.8969e-08, -2.6182e-08, -2.4826e-08, -2.3467e-08, -2.9882e-08],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    h2g.weight -= learning_rate * h2g.weight.grad\n",
    "    h2g.bias -= learning_rate * h2g.bias.grad\n",
    "h2g.weight, h2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24badddf-11c7-4c52-a31b-d7ef1912c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.4692e-07,  2.2701e-07,  2.0391e-07,  1.9728e-07,  2.5823e-07,\n",
       "         -9.2556e-10, -8.0872e-10, -7.6041e-10, -7.1028e-10, -9.3874e-10,\n",
       "         -3.4525e-08, -3.1154e-08, -2.9693e-08, -2.8006e-08, -3.5573e-08],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x2g.weight -= learning_rate * x2g.weight.grad\n",
    "    x2g.bias -= learning_rate * x2g.bias.grad\n",
    "x2g.weight, x2g.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97f58304-61da-46de-862d-b7e807e61d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    wte.weight -= learning_rate * wte.weight.grad\n",
    "wte.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ff10f-f64f-4801-b9ea-c40e15816684",
   "metadata": {},
   "source": [
    "## Forward Pass with Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00925f19-c83a-4549-b4ca-94f92ad301f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[35, 15, 32,  9,  5, 20, 30, 15],\n",
       "         [11,  9,  6, 20,  5,  0, 13, 21]]),\n",
       " tensor([[15, 32,  9,  5, 20, 30, 15, 11],\n",
       "         [ 9,  6, 20,  5,  0, 13, 21,  0]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = tok_for_training[:-1].view(B, T)\n",
    "x_2, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c68d0-cf29-431d-85d2-0d0276e55c70",
   "metadata": {},
   "source": [
    "## Input projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff392189-88e9-46a8-9ce1-b1aacad80e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 4]),\n",
       " tensor([[[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000, 1.0000]]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wte(x_2)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522598e4-600b-49ac-aca8-5ce33a9f8c8e",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f0c0ab4-a8da-4b22-ba93-92070f03527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 0.0000],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111]],\n",
       "\n",
       "        [[1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 0.0000],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111],\n",
       "         [1.1111, 1.1111, 1.1111, 1.1111]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5ddc4-503d-4a8c-8635-2a6b26d4750e",
   "metadata": {},
   "source": [
    "**Recurrent Block** Collapsed Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6d785-4282-431d-829b-e3ade8326816",
   "metadata": {},
   "source": [
    "h_t still resets to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a88d1ae-b4e8-46e0-9538-f94589005472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t = torch.zeros(B_batch, hidden_size) \n",
    "hs = []\n",
    "h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8ce97ab-1e58-4c12-b558-f9c216b341e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "tensor([[0.0955, 0.0955, 0.0955, 0.0955, 0.0955],\n",
      "        [0.0955, 0.0955, 0.0955, 0.0955, 0.0955]], grad_fn=<AddBackward0>)\n",
      "t: 1\n",
      "tensor([[0.1732, 0.1732, 0.1732, 0.1732, 0.1732],\n",
      "        [0.1732, 0.1732, 0.1732, 0.1732, 0.1732]], grad_fn=<AddBackward0>)\n",
      "t: 2\n",
      "tensor([[0.2761, 0.2761, 0.2761, 0.2761, 0.2761],\n",
      "        [0.2383, 0.2383, 0.2383, 0.2383, 0.2383]], grad_fn=<AddBackward0>)\n",
      "t: 3\n",
      "tensor([[0.3268, 0.3268, 0.3268, 0.3268, 0.3268],\n",
      "        [0.2940, 0.2940, 0.2940, 0.2940, 0.2940]], grad_fn=<AddBackward0>)\n",
      "t: 4\n",
      "tensor([[0.3713, 0.3713, 0.3713, 0.3713, 0.3713],\n",
      "        [0.3425, 0.3425, 0.3425, 0.3425, 0.3425]], grad_fn=<AddBackward0>)\n",
      "t: 5\n",
      "tensor([[0.4108, 0.4108, 0.4108, 0.4108, 0.4108],\n",
      "        [0.4110, 0.4110, 0.4110, 0.4110, 0.4110]], grad_fn=<AddBackward0>)\n",
      "t: 6\n",
      "tensor([[0.4461, 0.4461, 0.4461, 0.4461, 0.4461],\n",
      "        [0.4934, 0.4934, 0.4934, 0.4934, 0.4934]], grad_fn=<AddBackward0>)\n",
      "t: 7\n",
      "tensor([[0.4780, 0.4780, 0.4780, 0.4780, 0.4780],\n",
      "        [0.5210, 0.5210, 0.5210, 0.5210, 0.5210]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.0955, 0.0955, 0.0955, 0.0955, 0.0955]],\n",
       " \n",
       "         [[0.0955, 0.0955, 0.0955, 0.0955, 0.0955]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.1732, 0.1732, 0.1732, 0.1732, 0.1732]],\n",
       " \n",
       "         [[0.1732, 0.1732, 0.1732, 0.1732, 0.1732]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.2761, 0.2761, 0.2761, 0.2761, 0.2761]],\n",
       " \n",
       "         [[0.2383, 0.2383, 0.2383, 0.2383, 0.2383]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.3268, 0.3268, 0.3268, 0.3268, 0.3268]],\n",
       " \n",
       "         [[0.2940, 0.2940, 0.2940, 0.2940, 0.2940]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.3713, 0.3713, 0.3713, 0.3713, 0.3713]],\n",
       " \n",
       "         [[0.3425, 0.3425, 0.3425, 0.3425, 0.3425]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4108, 0.4108, 0.4108, 0.4108, 0.4108]],\n",
       " \n",
       "         [[0.4110, 0.4110, 0.4110, 0.4110, 0.4110]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4461, 0.4461, 0.4461, 0.4461, 0.4461]],\n",
       " \n",
       "         [[0.4934, 0.4934, 0.4934, 0.4934, 0.4934]]],\n",
       "        grad_fn=<UnsqueezeBackward0>),\n",
       " tensor([[[0.4780, 0.4780, 0.4780, 0.4780, 0.4780]],\n",
       " \n",
       "         [[0.5210, 0.5210, 0.5210, 0.5210, 0.5210]]],\n",
       "        grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    x_t = x[:, t, :]\n",
    "    h_prev = h_t\n",
    "    zx, rx, nx = x2g(x_t).chunk(3, dim=-1)\n",
    "    zh, rh, nh = h2g(h_prev).chunk(3, dim=-1)\n",
    "    z = torch.sigmoid(zx + zh)\n",
    "    r = torch.sigmoid(rx + rh)\n",
    "    n = torch.tanh(nx + r * nh)\n",
    "    h_t = (1 - z) * n + z * h_prev\n",
    "    \n",
    "    print(f't: {t}')\n",
    "    print(h_t)\n",
    "    hs.append(h_t.unsqueeze(1))\n",
    "\n",
    "hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5de2c-9cfb-4292-a7e9-4e45c2e2e913",
   "metadata": {},
   "source": [
    "combine weights back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80e35fdc-c488-4dac-87a1-dcc12a0e2abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 5]),\n",
       " tensor([[[0.0955, 0.0955, 0.0955, 0.0955, 0.0955],\n",
       "          [0.1732, 0.1732, 0.1732, 0.1732, 0.1732],\n",
       "          [0.2761, 0.2761, 0.2761, 0.2761, 0.2761],\n",
       "          [0.3268, 0.3268, 0.3268, 0.3268, 0.3268],\n",
       "          [0.3713, 0.3713, 0.3713, 0.3713, 0.3713],\n",
       "          [0.4108, 0.4108, 0.4108, 0.4108, 0.4108],\n",
       "          [0.4461, 0.4461, 0.4461, 0.4461, 0.4461],\n",
       "          [0.4780, 0.4780, 0.4780, 0.4780, 0.4780]],\n",
       " \n",
       "         [[0.0955, 0.0955, 0.0955, 0.0955, 0.0955],\n",
       "          [0.1732, 0.1732, 0.1732, 0.1732, 0.1732],\n",
       "          [0.2383, 0.2383, 0.2383, 0.2383, 0.2383],\n",
       "          [0.2940, 0.2940, 0.2940, 0.2940, 0.2940],\n",
       "          [0.3425, 0.3425, 0.3425, 0.3425, 0.3425],\n",
       "          [0.4110, 0.4110, 0.4110, 0.4110, 0.4110],\n",
       "          [0.4934, 0.4934, 0.4934, 0.4934, 0.4934],\n",
       "          [0.5210, 0.5210, 0.5210, 0.5210, 0.5210]]], grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat(hs, dim=1) \n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c53d-c55b-4940-852d-79498d489245",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f4b0ebe-0dab-458c-bba1-0d0617a9b294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1061, 0.1061, 0.1061, 0.1061, 0.1061],\n",
       "         [0.1925, 0.1925, 0.1925, 0.1925, 0.1925],\n",
       "         [0.3067, 0.3067, 0.3067, 0.3067, 0.3067],\n",
       "         [0.3631, 0.3631, 0.3631, 0.3631, 0.3631],\n",
       "         [0.4125, 0.4125, 0.4125, 0.4125, 0.4125],\n",
       "         [0.4564, 0.4564, 0.4564, 0.4564, 0.4564],\n",
       "         [0.4957, 0.4957, 0.4957, 0.4957, 0.4957],\n",
       "         [0.5311, 0.5311, 0.5311, 0.5311, 0.5311]],\n",
       "\n",
       "        [[0.1061, 0.1061, 0.1061, 0.1061, 0.1061],\n",
       "         [0.0000, 0.1925, 0.1925, 0.1925, 0.1925],\n",
       "         [0.2648, 0.2648, 0.2648, 0.2648, 0.2648],\n",
       "         [0.3267, 0.0000, 0.3267, 0.3267, 0.0000],\n",
       "         [0.3805, 0.3805, 0.0000, 0.3805, 0.3805],\n",
       "         [0.4566, 0.0000, 0.4566, 0.4566, 0.4566],\n",
       "         [0.5483, 0.5483, 0.5483, 0.5483, 0.5483],\n",
       "         [0.5789, 0.5789, 0.5789, 0.5789, 0.5789]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dropout(x)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1e47d-27d3-4039-8ea1-208d5fc30f29",
   "metadata": {},
   "source": [
    "**Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c2c2354-3b5c-4490-ac42-fd8474355857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 36]),\n",
       " tensor([[[0.6300, 0.5046, 0.5046, 0.5046, 0.5046, 0.6365, 0.5446, 0.5046,\n",
       "           0.5046, 0.5862, 0.5046, 0.5836, 0.5046, 0.5846, 0.5046, 0.6224,\n",
       "           0.5046, 0.5046, 0.5046, 0.5046, 0.6082, 0.5735, 0.5046, 0.5046,\n",
       "           0.5046, 0.5046, 0.5046, 0.5046, 0.5046, 0.5046, 0.5725, 0.5046,\n",
       "           0.5445, 0.5046, 0.5046, 0.5046],\n",
       "          [1.1426, 0.9151, 0.9151, 0.9151, 0.9151, 1.1545, 0.9877, 0.9151,\n",
       "           0.9151, 1.0632, 0.9151, 1.0585, 0.9151, 1.0604, 0.9151, 1.1288,\n",
       "           0.9151, 0.9151, 0.9151, 0.9151, 1.1031, 1.0401, 0.9151, 0.9151,\n",
       "           0.9151, 0.9151, 0.9151, 0.9151, 0.9151, 0.9151, 1.0384, 0.9151,\n",
       "           0.9876, 0.9151, 0.9151, 0.9151],\n",
       "          [1.8210, 1.4585, 1.4585, 1.4585, 1.4585, 1.8400, 1.5741, 1.4585,\n",
       "           1.4585, 1.6945, 1.4585, 1.6870, 1.4585, 1.6899, 1.4585, 1.7990,\n",
       "           1.4585, 1.4585, 1.4585, 1.4585, 1.7580, 1.6577, 1.4585, 1.4585,\n",
       "           1.4585, 1.4585, 1.4585, 1.4585, 1.4585, 1.4585, 1.6549, 1.4585,\n",
       "           1.5740, 1.4585, 1.4585, 1.4585],\n",
       "          [2.1555, 1.7264, 1.7264, 1.7264, 1.7264, 2.1780, 1.8634, 1.7264,\n",
       "           1.7264, 2.0058, 1.7264, 1.9970, 1.7264, 2.0004, 1.7264, 2.1295,\n",
       "           1.7264, 1.7264, 1.7264, 1.7264, 2.0810, 1.9623, 1.7264, 1.7264,\n",
       "           1.7264, 1.7264, 1.7264, 1.7264, 1.7264, 1.7264, 1.9589, 1.7264,\n",
       "           1.8632, 1.7264, 1.7264, 1.7264],\n",
       "          [2.4491, 1.9615, 1.9615, 1.9615, 1.9615, 2.4747, 2.1171, 1.9615,\n",
       "           1.9615, 2.2790, 1.9615, 2.2689, 1.9615, 2.2728, 1.9615, 2.4195,\n",
       "           1.9615, 1.9615, 1.9615, 1.9615, 2.3644, 2.2295, 1.9615, 1.9615,\n",
       "           1.9615, 1.9615, 1.9615, 1.9615, 1.9615, 1.9615, 2.2257, 1.9615,\n",
       "           2.1169, 1.9615, 1.9615, 1.9615],\n",
       "          [2.7095, 2.1701, 2.1701, 2.1701, 2.1701, 2.7378, 2.3422, 2.1701,\n",
       "           2.1701, 2.5213, 2.1701, 2.5102, 2.1701, 2.5145, 2.1701, 2.6768,\n",
       "           2.1701, 2.1701, 2.1701, 2.1701, 2.6158, 2.4665, 2.1701, 2.1701,\n",
       "           2.1701, 2.1701, 2.1701, 2.1701, 2.1701, 2.1701, 2.4623, 2.1701,\n",
       "           2.3420, 2.1701, 2.1701, 2.1701],\n",
       "          [2.9426, 2.3568, 2.3568, 2.3568, 2.3568, 2.9733, 2.5438, 2.3568,\n",
       "           2.3568, 2.7382, 2.3568, 2.7262, 2.3568, 2.7309, 2.3568, 2.9071,\n",
       "           2.3568, 2.3568, 2.3568, 2.3568, 2.8409, 2.6787, 2.3568, 2.3568,\n",
       "           2.3568, 2.3568, 2.3568, 2.3568, 2.3568, 2.3568, 2.6742, 2.3568,\n",
       "           2.5435, 2.3568, 2.3568, 2.3568],\n",
       "          [3.1529, 2.5253, 2.5253, 2.5253, 2.5253, 3.1858, 2.7256, 2.5253,\n",
       "           2.5253, 2.9339, 2.5253, 2.9210, 2.5253, 2.9260, 2.5253, 3.1148,\n",
       "           2.5253, 2.5253, 2.5253, 2.5253, 3.0440, 2.8702, 2.5253, 2.5253,\n",
       "           2.5253, 2.5253, 2.5253, 2.5253, 2.5253, 2.5253, 2.8653, 2.5253,\n",
       "           2.7253, 2.5253, 2.5253, 2.5253]],\n",
       " \n",
       "         [[0.6300, 0.5046, 0.5046, 0.5046, 0.5046, 0.6365, 0.5446, 0.5046,\n",
       "           0.5046, 0.5862, 0.5046, 0.5836, 0.5046, 0.5846, 0.5046, 0.6224,\n",
       "           0.5046, 0.5046, 0.5046, 0.5046, 0.6082, 0.5735, 0.5046, 0.5046,\n",
       "           0.5046, 0.5046, 0.5046, 0.5046, 0.5046, 0.5046, 0.5725, 0.5046,\n",
       "           0.5445, 0.5046, 0.5046, 0.5046],\n",
       "          [0.9010, 0.7328, 0.7328, 0.7328, 0.7328, 0.9243, 0.7909, 0.7328,\n",
       "           0.7328, 0.8513, 0.7328, 0.8403, 0.7328, 0.8490, 0.7328, 0.9037,\n",
       "           0.7328, 0.7328, 0.7328, 0.7328, 0.8922, 0.8265, 0.7328, 0.7328,\n",
       "           0.7328, 0.7328, 0.7328, 0.7328, 0.7328, 0.7328, 0.8252, 0.7328,\n",
       "           0.7908, 0.7328, 0.7328, 0.7328],\n",
       "          [1.5721, 1.2591, 1.2591, 1.2591, 1.2591, 1.5885, 1.3590, 1.2591,\n",
       "           1.2591, 1.4629, 1.2591, 1.4564, 1.2591, 1.4589, 1.2591, 1.5531,\n",
       "           1.2591, 1.2591, 1.2591, 1.2591, 1.5177, 1.4311, 1.2591, 1.2591,\n",
       "           1.2591, 1.2591, 1.2591, 1.2591, 1.2591, 1.2591, 1.4287, 1.2591,\n",
       "           1.3588, 1.2591, 1.2591, 1.2591],\n",
       "          [1.1181, 0.9333, 0.9333, 0.9333, 0.9333, 1.1771, 1.0072, 0.9333,\n",
       "           0.9333, 1.0841, 0.9333, 1.0550, 0.9333, 1.0812, 0.9333, 1.1509,\n",
       "           0.9333, 0.9333, 0.9333, 0.9333, 1.1413, 1.0924, 0.9333, 0.9333,\n",
       "           0.9333, 0.9333, 0.9333, 0.9333, 0.9333, 0.9333, 1.0379, 0.9333,\n",
       "           1.0071, 0.9333, 0.9333, 0.9333],\n",
       "          [1.8467, 1.4460, 1.4460, 1.4460, 1.4460, 1.8247, 1.5609, 1.4460,\n",
       "           1.4460, 1.6803, 1.4460, 1.7296, 1.4460, 1.6758, 1.4460, 1.7840,\n",
       "           1.4460, 1.4460, 1.4460, 1.4460, 1.7248, 1.6314, 1.4460, 1.4460,\n",
       "           1.4460, 1.4460, 1.4460, 1.4460, 1.4460, 1.4460, 1.6288, 1.4460,\n",
       "           1.5607, 1.4460, 1.4460, 1.4460],\n",
       "          [2.1349, 1.7358, 1.7358, 1.7358, 1.7358, 2.1902, 1.8736, 1.7358,\n",
       "           1.7358, 2.0170, 1.7358, 1.9910, 1.7358, 2.0115, 1.7358, 2.1414,\n",
       "           1.7358, 1.7358, 1.7358, 1.7358, 2.1381, 2.0324, 1.7358, 1.7358,\n",
       "           1.7358, 1.7358, 1.7358, 1.7358, 1.7358, 1.7358, 1.9551, 1.7358,\n",
       "           1.8734, 1.7358, 1.7358, 1.7358],\n",
       "          [3.2549, 2.6069, 2.6069, 2.6069, 2.6069, 3.2889, 2.8137, 2.6069,\n",
       "           2.6069, 3.0288, 2.6069, 3.0154, 2.6069, 3.0206, 2.6069, 3.2155,\n",
       "           2.6069, 2.6069, 2.6069, 2.6069, 3.1424, 2.9630, 2.6069, 2.6069,\n",
       "           2.6069, 2.6069, 2.6069, 2.6069, 2.6069, 2.6069, 2.9580, 2.6069,\n",
       "           2.8134, 2.6069, 2.6069, 2.6069],\n",
       "          [3.4368, 2.7526, 2.7526, 2.7526, 2.7526, 3.4727, 2.9710, 2.7526,\n",
       "           2.7526, 3.1981, 2.7526, 3.1840, 2.7526, 3.1895, 2.7526, 3.3953,\n",
       "           2.7526, 2.7526, 2.7526, 2.7526, 3.3181, 3.1286, 2.7526, 2.7526,\n",
       "           2.7526, 2.7526, 2.7526, 2.7526, 2.7526, 2.7526, 3.1233, 2.7526,\n",
       "           2.9707, 2.7526, 2.7526, 2.7526]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(x)\n",
    "logits.shape, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed1cae-6af9-4211-82b1-8930196c48c3",
   "metadata": {},
   "source": [
    "### Updated Loss calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c101fbc-97fc-4dc2-b99e-1cff59d22f5d",
   "metadata": {},
   "source": [
    "Now we'll calculate the updated loss.  Our first pass's loss was 3.5835. Since we're passing through the same example and used a fairly high learning rate we should see a significant improvement with just 1 learning pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a12e542-dda9-4cb4-9611-bcb157515806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5835, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2c2eb99-d188-4de7-a4ee-27917e3cec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) tensor(3.3731, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_flat = y.view(-1)\n",
    "logits_flat = logits.view(-1, logits.size(-1))\n",
    "updated_loss = F.cross_entropy(logits_flat, y_flat)\n",
    "print(updated_loss.shape, updated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53363221-ba7b-49f8-8f6a-88c6db647277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 round of training resulted in an loss improvment of 0.2105'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'1 round of training resulted in an loss improvment of {loss.item() - updated_loss.item():.4f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56dfda-a142-40b3-b66f-60cb6cae0a8e",
   "metadata": {},
   "source": [
    "# SUCCESS!\n",
    "Our training improved the loss by about **~6%** (amount may vary since we didn't set a seed). There are flaws with this, mainly passing the same example through a second time, but this helps show the fundamentals of what learning does inside a GPT-2 style model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b7955-c155-4f69-8b42-69d105309887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08f0e0-e068-4ab6-a041-00fa9c081dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
